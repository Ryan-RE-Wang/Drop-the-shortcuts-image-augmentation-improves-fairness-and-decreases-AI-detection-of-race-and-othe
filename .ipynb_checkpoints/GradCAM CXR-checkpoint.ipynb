{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import cv2 as cv\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import pandas as pd\n",
    "import skimage.transform as st\n",
    "import os\n",
    "from PIL import Image\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import itertools\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, roc_auc_score, accuracy_score\n",
    "from transformation import *\n",
    "from utilities import *\n",
    "from calculate_disparity import *\n",
    "from GradCAM import *\n",
    " \n",
    "print(tf.__version__)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "tf.config.set_visible_devices(devices=gpus[1], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2021\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset='mimic', label_type='No Finding'):\n",
    "    np.random.seed(2021)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    if (dataset == 'mimic'):\n",
    "        filename = 'data/mimic_test.tfrecords'\n",
    "    elif (dataset == 'chexpert'):\n",
    "        filename = '../Data/Chexpert_test.tfrecords'\n",
    "        \n",
    "    raw_dataset = tf.data.TFRecordDataset(filename)\n",
    "    for raw_record in raw_dataset:\n",
    "        sub_y = []\n",
    "\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "            \n",
    "        if (example.features.feature[label_type].float_list.value[0] == 1):\n",
    "            \n",
    "            nparr = np.fromstring(example.features.feature['jpg_bytes'].bytes_list.value[0], np.uint8)\n",
    "            img_np = cv.imdecode(nparr, cv.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            X.append(tf.reshape(np.float32(st.resize(img_np, (224, 224))), [224, 224, 1]))\n",
    "    \n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model_diseases()\n",
    "\n",
    "# model.load_weights('checkpoints/model_mimic_proposed')\n",
    "model.load_weights('checkpoints/model_mimic_baseline')\n",
    "\n",
    "input_layer = model.get_layer(model.layers[0].name)\n",
    "upsampling = model.get_layer(model.layers[1].name)\n",
    "denset121 = model.get_layer(model.layers[2].name)\n",
    "\n",
    "last_conv_layer_model = tf.keras.Sequential()\n",
    "last_conv_layer_model.add(input_layer)\n",
    "last_conv_layer_model.add(upsampling)\n",
    "last_conv_layer_model.add(tf.keras.Model(denset121.inputs, denset121.get_layer('relu').output))\n",
    "\n",
    "# Second, we create a model that maps the activations of the last conv\n",
    "# layer to the final class predictions\n",
    "classifier_input = tf.keras.Input(shape=denset121.layers[-2].output.shape[1:])\n",
    "x = classifier_input\n",
    "x = denset121.get_layer(denset121.layers[-1].name)(x)\n",
    "x = model.get_layer(model.layers[-1].name)(x)\n",
    "classifier_model = tf.keras.Model(classifier_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-guatemala",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Labels_diseases = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
    "\n",
    "count = 0\n",
    "target_class = 0\n",
    "img_array = get_data(dataset='mimic', label_type=Labels_diseases[target_class])\n",
    "\n",
    "for id in range(len(img_array)):\n",
    "\n",
    "    pred_proba = model(img_array[id:id+1]) \n",
    "#     if (pred_proba[0][target_class] >= 0.5):\n",
    "    if (os.path.exists(\"rsna_imgs/proposed/{}_{}.jpeg\".format(Labels_diseases[target_class], id))):\n",
    "        jet_heatmap = show_heatmap(img_array[id:id+1], last_conv_layer_model, classifier_model, target_class)\n",
    "        plt.imshow(np.reshape(jet_heatmap, (224, 224, 3)))\n",
    "#         plt.savefig(\"rsna_imgs/proposed/{}_{}.jpeg\".format(Labels_diseases[target_class], id))\n",
    "        plt.savefig(\"rsna_imgs/baseline/{}_{}.jpeg\".format(Labels_diseases[target_class], id))\n",
    "        plt.show()\n",
    "        count += 1\n",
    "    \n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
