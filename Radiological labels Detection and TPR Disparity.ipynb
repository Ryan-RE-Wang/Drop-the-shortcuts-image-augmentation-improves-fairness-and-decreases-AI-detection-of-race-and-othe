{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformation import *\n",
    "from utilities import *\n",
    "from calculate_disparity import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import warnings\n",
    "import skimage.transform as st\n",
    "import gc\n",
    "import os\n",
    "\n",
    "print(tf.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "tf.config.set_visible_devices(devices=gpus[1], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2021\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "Labels_diseases = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Chexpert_demo.csv', index_col=0)\n",
    "\n",
    "\n",
    "def get_age_interval(age):\n",
    "    if (age < 40):\n",
    "        return 0\n",
    "    elif (40 <= age < 60):\n",
    "        return 1\n",
    "    elif (60 <= age < 80):\n",
    "        return 2\n",
    "    elif (age >= 80):\n",
    "        return 3\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def get_gender(gender):\n",
    "    if (gender=='Female'):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset='mimic', data_split='test', types, feature_type=-1, random_aug=False):\n",
    "    np.random.seed(2021)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    if (dataset == 'mimic'):\n",
    "        if (data_split == 'train'):\n",
    "            filename = ['data/mimic_train.tfrecords']\n",
    "        elif(data_split == 'val'):\n",
    "            filename = 'data/mimic_val.tfrecords'\n",
    "        else:\n",
    "            filename = 'data/mimic_test.tfrecords'\n",
    "    elif (dataset == 'chexpert'):\n",
    "        if (data_split == 'train'):\n",
    "            filename = '../Data/Chexpert_train.tfrecords'\n",
    "        else:\n",
    "            filename = '../Data/Chexpert_test.tfrecords'\n",
    "        \n",
    "    raw_dataset = tf.data.TFRecordDataset(filename)\n",
    "    for raw_record in raw_dataset:\n",
    "        sub_y = []\n",
    "\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        \n",
    "        if (dataset == 'mimic'):\n",
    "            if (types == 'race'):\n",
    "                race = example.features.feature['race'].int64_list.value[0]\n",
    "                feature = race\n",
    "            elif (types == 'age'):\n",
    "                age = example.features.feature['age'].int64_list.value[0]\n",
    "                if (age > 0):\n",
    "                    age -= 1\n",
    "                feature = age\n",
    "            else:\n",
    "                gender = example.features.feature['gender'].int64_list.value[0]\n",
    "                feature = gender\n",
    "            \n",
    "        elif (dataset == 'chexpert'):\n",
    "            id = str(example.features.feature['id'].int64_list.value[0])\n",
    "            \n",
    "            if (types == 'race'):\n",
    "                race = example.features.feature['race'].int64_list.value[0]\n",
    "                feature = race\n",
    "            elif (types == 'age'):\n",
    "                age = get_age_interval(df.loc[df['PATIENT']=='patient{i}'.format(i=id.zfill(5)), 'AGE_AT_CXR'].values[0])\n",
    "                feature = age\n",
    "            else:\n",
    "                gender = get_gender(df.loc[df['PATIENT']=='patient{i}'.format(i=id.zfill(5)), 'GENDER'].values[0])\n",
    "                feature = gender\n",
    "        \n",
    "        if not (race == 0 or race == 1 or race == 4):\n",
    "            continue\n",
    "            \n",
    "        if (feature_type == -1 or feature == feature_type):\n",
    "\n",
    "            sub_y.append(1 if example.features.feature['Atelectasis'].float_list.value[0] == 1 else 0)\n",
    "            sub_y.append(1 if example.features.feature['Cardiomegaly'].float_list.value[0] == 1 else 0)\n",
    "            sub_y.append(1 if example.features.feature['Consolidation'].float_list.value[0] == 1 else 0)\n",
    "            sub_y.append(1 if example.features.feature['Edema'].float_list.value[0] == 1 else 0)\n",
    "            sub_y.append(1 if example.features.feature['Enlarged Cardiomediastinum'].float_list.value[0] == 1 else 0)\n",
    "            sub_y.append(1 if example.features.feature['Fracture'].float_list.value[0] == 1 else 0)\n",
    "            sub_y.append(1 if example.features.feature['Lung Lesion'].float_list.value[0] == 1 else 0)\n",
    "            sub_y.append(1 if example.features.feature['Lung Opacity'].float_list.value[0] == 1 else 0)\n",
    "            sub_y.append(1 if example.features.feature['No Finding'].float_list.value[0] == 1 else 0)\n",
    "            sub_y.append(1 if example.features.feature['Pleural Effusion'].float_list.value[0] == 1 else 0)\n",
    "            sub_y.append(1 if example.features.feature['Pleural Other'].float_list.value[0] == 1 else 0)\n",
    "            sub_y.append(1 if example.features.feature['Pneumonia'].float_list.value[0] == 1 else 0)\n",
    "            sub_y.append(1 if example.features.feature['Pneumothorax'].float_list.value[0] == 1 else 0)\n",
    "            sub_y.append(1 if example.features.feature['Support Devices'].float_list.value[0] == 1 else 0)\n",
    "            \n",
    "            nparr = np.fromstring(example.features.feature['jpg_bytes'].bytes_list.value[0], np.uint8)\n",
    "            img_np = cv.imdecode(nparr, cv.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if (random_aug==True):\n",
    "                rand = np.random.randint(0, 4)\n",
    "                if (rand == 0):\n",
    "                    seed = np.random.uniform(-np.pi/4, np.pi/4)\n",
    "                    img_np = shear_transform(seed, img_np)\n",
    "                elif (rand == 1):\n",
    "                    angle = np.random.uniform(-90, 90)\n",
    "                    img_np = rotation_transformation(angle, img_np)\n",
    "                elif (rand == 2):\n",
    "                    img_np = fish(img_np, 0.4)\n",
    "                else:\n",
    "                    seed = np.random.uniform(0.4, 1)\n",
    "                    img_np = scaling_transformation(seed, img_np)\n",
    "\n",
    "            X.append(np.float32(st.resize(img_np, (224, 224))))\n",
    "            y.append(sub_y)            \n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-rescue",
   "metadata": {},
   "source": [
    "# Radiological labels Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'checkpoints/model_mimic_proposed'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min')\n",
    "\n",
    "callback = [tf.keras.callbacks.LearningRateScheduler(scheduler),\n",
    "            tf.keras.callbacks.EarlyStopping(mode='min', patience=4, monitor='val_loss'),\n",
    "            model_checkpoint_callback]\n",
    "\n",
    "# mimic\n",
    "X_train, y_train = get_data(dataset='mimic', data_split='train', feature_type=-1, combine=True)\n",
    "X_val, y_val = get_data(dataset='mimic', data_split='val', feature_type=-1, combine=True)\n",
    "\n",
    "# chexpert\n",
    "# X_train, y_train = get_data(dataset='chexpert', data_split='train', feature_type=-1, combine=True)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=2021)\n",
    "\n",
    "model = define_model_diseases()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val), callbacks=callback, batch_size=BATCH_SIZE)\n",
    "\n",
    "y_preds = model.predict(X_val)\n",
    "\n",
    "best_thresh = cal_best_thresh(y_val, y_preds)\n",
    "\n",
    "np.savetxt('mimic_proposed_thresh.txt', [best_thresh])\n",
    "\n",
    "del X_train, y_train\n",
    "del X_val, y_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-inspector",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test = get_data('mimic', 'test', -1)\n",
    "\n",
    "model = define_model_diseases()\n",
    "\n",
    "model.load_weights('checkpoints/model_mimic_baseline')\n",
    "y_preds = model.predict(X_test)\n",
    "plot_roc(y_test, y_preds, 'ROC', Label_diseases)\n",
    "print(test(y_preds, y_test))\n",
    "\n",
    "model.load_weights('checkpoints/model_mimic_proposed')\n",
    "y_preds = model.predict(X_test)\n",
    "plot_roc(y_test, y_preds, 'ROC', Label_diseases)\n",
    "print(test(y_preds, y_test))\n",
    "\n",
    "model.load_weights('checkpoints/model_chexpert_baseline')\n",
    "y_preds = model.predict(X_test)\n",
    "plot_roc(y_test, y_preds, 'ROC', Label_diseases)\n",
    "print(test(y_preds, y_test))\n",
    "\n",
    "model.load_weights('checkpoints/model_chexpert_proposed')\n",
    "y_preds = model.predict(X_test)\n",
    "plot_roc(y_test, y_preds, 'ROC', Label_diseases)\n",
    "print(test(y_preds, y_test))\n",
    "\n",
    "del model \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-northeast",
   "metadata": {},
   "source": [
    "# Calculate TPR Disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_white, y_test_white = get_data('mimic', 'test', 'race', 0, True)\n",
    "X_test_black, y_test_black = get_data('mimic', 'test', 'race', 1, True)\n",
    "X_test_asia, y_test_asia = get_data('mimic', 'test', 'race', 4, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model_diseases()\n",
    "\n",
    "model.load_weights('checkpoints/model_mimic_baseline')\n",
    "best_thresh = np.loadtxt('original_thresh.txt')\n",
    "\n",
    "# model.load_weights('checkpoints/model_mimic_proposed')\n",
    "# best_thresh = np.loadtxt('mimic_combine_thresh.txt')\n",
    "\n",
    "# model.load_weights('checkpoints/model_chexpert_baseline')\n",
    "# best_thresh = np.loadtxt('chexpert_thresh.txt')\n",
    "\n",
    "# model.load_weights('checkpoints/model_chexpert_proposed')\n",
    "# best_thresh = np.loadtxt('chexpert_combine_thresh.txt')\n",
    "\n",
    "y_preds_white = model.predict(X_test_white)\n",
    "y_preds_black = model.predict(X_test_black)\n",
    "y_preds_asia = model.predict(X_test_asia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity = []\n",
    "tprs_white = []\n",
    "tprs_black = []\n",
    "tprs_asia = []\n",
    "for i in range(14):\n",
    "    tpr_white = get_tpr(y_test_white[:, i], y_preds_white[:, i], best_thresh[i])\n",
    "    tpr_black = get_tpr(y_test_black[:, i], y_preds_black[:, i], best_thresh[i])\n",
    "    tpr_asia = get_tpr(y_test_asia[:, i], y_preds_asia[:, i], best_thresh[i])\n",
    "\n",
    "    median = np.median([tpr_white, tpr_black, tpr_asia])\n",
    "    gap = np.abs(tpr_white-median) + np.abs(tpr_black-median) + np.abs(tpr_asia-median)\n",
    "    disparity.append(gap)\n",
    "    tprs_white.append(tpr_white-median)\n",
    "    tprs_black.append(tpr_black-median)\n",
    "    tprs_asia.append(tpr_asia-median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(disparity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(test(y_preds_white, y_test_white))\n",
    "print(test(y_preds_black, y_test_black))\n",
    "print(test(y_preds_asia, y_test_asia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "result.append(disparity)\n",
    "result.append(tprs_white)\n",
    "result.append(tprs_black)\n",
    "result.append(tprs_asia)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
