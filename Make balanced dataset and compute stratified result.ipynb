{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "blank-video",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 19 14:47:24 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.67       Driver Version: 460.67       CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 3090    Off  | 00000000:65:00.0 Off |                  N/A |\r\n",
      "| 71%   63C    P2   278W / 370W |  21885MiB / 24265MiB |     65%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 3090    Off  | 00000000:B3:00.0 Off |                  N/A |\r\n",
      "|  0%   49C    P8    45W / 370W |    421MiB / 24268MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     16032      G   /usr/lib/xorg/Xorg                 41MiB |\r\n",
      "|    0   N/A  N/A     19191      C   python                          21079MiB |\r\n",
      "|    0   N/A  N/A     21538      C   /opt/tljh/user/bin/python         761MiB |\r\n",
      "|    1   N/A  N/A     16032      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    1   N/A  N/A     28885      C   /opt/tljh/user/bin/python         413MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fifty-evening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import warnings\n",
    "import skimage.transform as st\n",
    "import gc\n",
    "from IPython import display\n",
    "from load_data import *\n",
    "from models import *\n",
    "from evaluation import *\n",
    "\n",
    "print(tf.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "tf.config.set_visible_devices(devices=gpus[0], device_type='GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-jersey",
   "metadata": {},
   "source": [
    "# Make balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "soviet-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "\n",
    "race_array = []\n",
    "age_array = []\n",
    "gender_array = [] \n",
    "study_ids = []\n",
    "subject_ids = []\n",
    "img_array = []\n",
    "diseases_array = []\n",
    "    \n",
    "filename = ['data/mimic_val_proposed.tfrecords']\n",
    "\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset(filename)\n",
    "for raw_record in raw_dataset:\n",
    "    sub_y = []\n",
    "\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "\n",
    "#     study_id = example.features.feature['study_id'].int64_list.value[0]\n",
    "#     subject_id = example.features.feature['subject_id'].int64_list.value[0]\n",
    "    \n",
    "    race = example.features.feature['race'].int64_list.value[0]\n",
    "    if (race == 4):\n",
    "        race = 2\n",
    "        \n",
    "    age = example.features.feature['age'].int64_list.value[0]\n",
    "    if (age > 0):\n",
    "        age -= 1\n",
    "        \n",
    "    gender = example.features.feature['gender'].int64_list.value[0]\n",
    "    \n",
    "    sub_y = []\n",
    "    sub_y.append(1 if example.features.feature['Atelectasis'].float_list.value[0] == 1 else 0)\n",
    "    sub_y.append(1 if example.features.feature['Cardiomegaly'].float_list.value[0] == 1 else 0)\n",
    "    sub_y.append(1 if example.features.feature['Consolidation'].float_list.value[0] == 1 else 0)\n",
    "    sub_y.append(1 if example.features.feature['Edema'].float_list.value[0] == 1 else 0)\n",
    "    sub_y.append(1 if example.features.feature['Enlarged Cardiomediastinum'].float_list.value[0] == 1 else 0)\n",
    "    sub_y.append(1 if example.features.feature['Fracture'].float_list.value[0] == 1 else 0)\n",
    "    sub_y.append(1 if example.features.feature['Lung Lesion'].float_list.value[0] == 1 else 0)\n",
    "    sub_y.append(1 if example.features.feature['Lung Opacity'].float_list.value[0] == 1 else 0)\n",
    "    sub_y.append(1 if example.features.feature['No Finding'].float_list.value[0] == 1 else 0)\n",
    "    sub_y.append(1 if example.features.feature['Pleural Effusion'].float_list.value[0] == 1 else 0)\n",
    "    sub_y.append(1 if example.features.feature['Pleural Other'].float_list.value[0] == 1 else 0)\n",
    "    sub_y.append(1 if example.features.feature['Pneumonia'].float_list.value[0] == 1 else 0)\n",
    "    sub_y.append(1 if example.features.feature['Pneumothorax'].float_list.value[0] == 1 else 0)\n",
    "    sub_y.append(1 if example.features.feature['Support Devices'].float_list.value[0] == 1 else 0)\n",
    "    \n",
    "    img = example.features.feature['jpg_bytes'].bytes_list.value[0], np.uint8\n",
    "\n",
    "    diseases_array.append(sub_y)\n",
    "#     study_ids.append(study_id)\n",
    "#     subject_ids.append(subject_id)\n",
    "    race_array.append(race)\n",
    "    age_array.append(age)\n",
    "    gender_array.append(gender)\n",
    "    img_array.append(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "musical-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Race\":race_array, \"Age\":age_array, \"Gender\":gender_array})\n",
    "\n",
    "g_ = df.groupby(['Race', 'Age', 'Gender'])\n",
    "df_ = g_.apply(lambda x: x.sample(g_.size().min())).reset_index(level=[0, 1, 2], drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "optional-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_.index.values\n",
    "\n",
    "diseases_array = np.array(diseases_array)[idx]\n",
    "# study_ids = np.array(study_ids)[idx]\n",
    "# subject_ids = np.array(subject_ids)[idx]\n",
    "race_array = np.array(race_array)[idx]\n",
    "age_array = np.array(age_array)[idx]\n",
    "gender_array = np.array(gender_array)[idx]\n",
    "img_array = np.array(img_array)[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "biblical-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_file = 'data/mimic_val_proposed_balanced.tfrecords'\n",
    "Labels_diseases = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
    "\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "    for i in range(len(img_array)):\n",
    "        example = tf.train.Example()\n",
    "        \n",
    "        example.features.feature['jpg_bytes'].bytes_list.value.append(img_array[i][0])  \n",
    "                \n",
    "        example.features.feature['race'].int64_list.value.append(race_array[i])\n",
    "        \n",
    "#         example.features.feature['subject_id'].int64_list.value.append(subject_ids[i])\n",
    "        \n",
    "#         example.features.feature['study_id'].int64_list.value.append(study_ids[i])\n",
    "        \n",
    "        for j in range(14):\n",
    "            example.features.feature[Labels_diseases[j]].float_list.value.append(diseases_array[i][j])\n",
    "\n",
    "        example.features.feature['age'].int64_list.value.append(age_array[i])\n",
    "                \n",
    "        example.features.feature['gender'].int64_list.value.append(gender_array[i])\n",
    "        \n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-reynolds",
   "metadata": {},
   "source": [
    "# Evaluate model on strtified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-electronics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).save_counter\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).save_counter\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).save_counter\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).save_counter\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "aug_method_list = ['rotation', 'shear', 'scaling', 'fisheye']\n",
    "dataset = 'mimic'\n",
    "data_split = 'test'\n",
    "task = 'disease'\n",
    "archi = 'densenet'\n",
    "group_name = {'race': ['white', 'black', 'asian'], 'gender': ['male', 'female'], 'age': ['0_40', '40_60', '60_80', '80+']}\n",
    "group_type = {'race': [0, 1, 4], 'gender': [0, 1], 'age': [0, 1, 2, 3]}\n",
    "\n",
    "for group in ['age']:\n",
    "    for i, v in enumerate(group_name[group]):\n",
    "        name = 'stratified_{v}'.format(v=v)\n",
    "        model_name = 'model_densenet_mimic_ERM_{name}_proposed'.format(name=name)\n",
    "        model = define_model(nodes=14, archi=archi)\n",
    "\n",
    "        checkpoint_filepath = 'checkpoints/'+model_name\n",
    "\n",
    "        checkpoint = tf.train.Checkpoint(model)\n",
    "        manager = tf.train.CheckpointManager(checkpoint, directory=checkpoint_filepath, max_to_keep=1, checkpoint_name=model_name)\n",
    "\n",
    "        model.load_weights(manager.checkpoints[0])\n",
    "\n",
    "        all_preds = []\n",
    "\n",
    "        for i2 in aug_method_list:\n",
    "            filepaths = glob.glob('data/{dataset}_{data_split}_{aug_method}*'.format(dataset=dataset, data_split=data_split, aug_method=i2))\n",
    "\n",
    "            for j in filepaths:\n",
    "\n",
    "                splits = re.split('_|\\.|\\/', j)\n",
    "\n",
    "                X_test, y_test = get_stratified_data(aug_method='_'+splits[3], dataset=splits[1], data_split=splits[2], group=group, group_type=group_type[group][i])\n",
    "\n",
    "                all_preds.append(model.predict(X_test))\n",
    "\n",
    "        y_preds = np.mean(all_preds, axis=0)\n",
    "\n",
    "        filename = 'predictions/{model_name}_on_aug'.format(model_name=model_name)\n",
    "\n",
    "        with open(filename, \"wb\") as fp:\n",
    "            pickle.dump(y_preds, fp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "printable-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_method = ''\n",
    "dataset = 'mimic'\n",
    "task = 'disease'\n",
    "\n",
    "X_test, y_test, demo = get_data(aug_method=aug_method, dataset=dataset, data_split='test', task=task, return_demo=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "turned-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_result(y_test, demo, result_name, group, testdata):\n",
    "    group_type = {'race': [0, 1, 4], 'gender': [0, 1], 'age': [0, 1, 2, 3]}\n",
    "    group_name = {'race': ['white', 'black', 'asian'], 'gender': ['male', 'female'], 'age': ['0_40', '40_60', '60_80', '80+']}\n",
    "\n",
    "    dfs = []\n",
    "    for j, target in enumerate(group_type[group]):\n",
    "\n",
    "        idx = demo[:, list(group_name).index(group)] == target\n",
    "\n",
    "        dfs_disease = []\n",
    "        \n",
    "        file = 'predictions/model_densenet_mimic_ERM_stratified_{group_name}_proposed_on_{testdata}'.format(group=group, group_name=group_name[group][j], testdata=testdata)\n",
    "        best_thresh = np.loadtxt('thresh/model_densenet_mimic_ERM_stratified_{group_name}_proposed_thresh.txt'.format(group_name=group_name[group][j]))\n",
    "        with open(file, \"rb\") as fp:   # Unpickling\n",
    "            y_preds = pickle.load(fp)\n",
    "        fp.close()\n",
    "            \n",
    "        for k in range(14):\n",
    "\n",
    "            dfs_disease.append(test(y_preds[:, k], y_test[idx, k], best_thresh[k]))\n",
    "\n",
    "        dfs.append(dfs_disease)\n",
    "\n",
    "    with open(\"results/{i}_on_{testdata}_{group}_results\".format(i=result_name, testdata=testdata, group=group), \"wb\") as fp:\n",
    "        pickle.dump(dfs, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hourly-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_name = 'densenet_mimic_ERM_stratified_proposed'\n",
    "\n",
    "compute_result(y_test, demo, result_name, 'race', 'original')\n",
    "\n",
    "result_name = 'densenet_mimic_ERM_stratified_proposed'\n",
    "\n",
    "compute_result(y_test, demo, result_name, 'race', 'aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "funky-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_name = 'densenet_mimic_ERM_stratified_proposed'\n",
    "\n",
    "compute_result(y_test, demo, result_name, 'age', 'original')\n",
    "\n",
    "result_name = 'densenet_mimic_ERM_stratified_proposed'\n",
    "\n",
    "compute_result(y_test, demo, result_name, 'age', 'aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fitting-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_name = 'densenet_mimic_ERM_stratified_proposed'\n",
    "\n",
    "compute_result(y_test, demo, result_name, 'gender', 'original')\n",
    "\n",
    "result_name = 'densenet_mimic_ERM_stratified_proposed'\n",
    "\n",
    "compute_result(y_test, demo, result_name, 'gender', 'aug')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-owner",
   "metadata": {},
   "source": [
    "## 3D MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "prime-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_result(y_test, demo, mode, group, testdata):\n",
    "    group_type = {'race': [0, 1], 'gender': [0, 1], 'age': [0, 1]}\n",
    "    group_name = {'race': ['white', 'others'], 'gender': ['female', 'male'], 'age': ['young', 'old']}\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for j in group_type[group]:\n",
    "\n",
    "        idx = demo == j\n",
    "        \n",
    "        file = 'predictions/3D_CNN_AD_CN_stratified_{group_name}{i}_on_{testdata}'.format(i=mode, group_name=group_name[group][j], testdata=testdata)\n",
    "        best_thresh = np.loadtxt('thresh/3D_CNN_AD_CN_stratified_{group_name}_thresh.txt'.format(group_name=group_name[group][j]))\n",
    "        with open(file, \"rb\") as fp:   # Unpickling\n",
    "            y_preds = pickle.load(fp)\n",
    "            \n",
    "        print(file)\n",
    "\n",
    "        dfs.append(test(y_preds, y_test[idx], best_thresh))\n",
    "\n",
    "    with open(\"results/3D_CNN_AD_CN_stratified{i}_on_{testdata}_{group}_results\".format(i=mode, group=group, testdata=testdata), \"wb\") as fp:\n",
    "        pickle.dump(dfs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adult-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_new.csv')\n",
    "data_path = '../../../mnt/usb/kuopc/ADNI_B1/MPR__GradWarp__B1_Correction_crop/'\n",
    "\n",
    "df = df.loc[df['Group'] != 'MCI']\n",
    "df = df.loc[df['Split'] == 'test']\n",
    "\n",
    "df['Group'] = df['Group'].replace(['CN', 'AD'], [0, 1])\n",
    "df['Sex'] = df['Sex'].replace(['F', 'M'], [0, 1])\n",
    "df['Age'] = np.where(df['Age'] <= 75, 0, 1)\n",
    "df['Race'] = np.where(df['Race'] < 1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = ''\n",
    "\n",
    "compute_result(df['Group'].values, df['Sex'].values, mode, 'gender', 'original')\n",
    "\n",
    "mode = ''\n",
    "\n",
    "compute_result(df['Group'].values, df['Sex'].values, mode, 'gender', 'aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = '_proposed'\n",
    "\n",
    "compute_result(df['Group'].values, df['Sex'].values, mode, 'gender', 'original')\n",
    "\n",
    "mode = '_proposed'\n",
    "\n",
    "compute_result(df['Group'].values, df['Sex'].values, mode, 'gender', 'aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = ''\n",
    "\n",
    "compute_result(df['Group'].values, df['Age'].values, mode, 'age', 'original')\n",
    "\n",
    "mode = ''\n",
    "\n",
    "compute_result(df['Group'].values, df['Age'].values, mode, 'age', 'aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = '_proposed'\n",
    "\n",
    "compute_result(df['Group'].values, df['Age'].values, mode, 'age', 'original')\n",
    "\n",
    "mode = '_proposed'\n",
    "\n",
    "compute_result(df['Group'].values, df['Age'].values, mode, 'age', 'aug')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
