{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "valued-throat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 18 20:52:31 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.67       Driver Version: 460.67       CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 3090    Off  | 00000000:65:00.0 Off |                  N/A |\r\n",
      "| 64%   56C    P8    21W / 370W |   3404MiB / 24265MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 3090    Off  | 00000000:B3:00.0 Off |                  N/A |\r\n",
      "| 92%   78C    P2   332W / 370W |  23982MiB / 24268MiB |     90%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1741      G   /usr/lib/xorg/Xorg                 32MiB |\r\n",
      "|    0   N/A  N/A      3270      G   /usr/bin/gnome-shell               98MiB |\r\n",
      "|    0   N/A  N/A      8481      G   /usr/lib/xorg/Xorg                 49MiB |\r\n",
      "|    0   N/A  N/A     22635      C   /opt/tljh/user/bin/python        1825MiB |\r\n",
      "|    0   N/A  N/A     23156      C   /opt/tljh/user/bin/python        1393MiB |\r\n",
      "|    1   N/A  N/A      1741      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    1   N/A  N/A      8481      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    1   N/A  N/A     25210      C   python                          23969MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "packed-mumbai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu113\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve, auc\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from scipy.ndimage import zoom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torchsummary import summary\n",
    "from transformation_3d import *\n",
    "from resnet3d import *\n",
    "from Custom_losses_3d import *\n",
    "from evaluation import *\n",
    "from load_data import *\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fourth-fleet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjacent-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (96, 96, 96)\n",
    "\n",
    "class ADNI_3D_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv, path, transform, task):\n",
    "\n",
    "        self.csv = csv\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.task = task\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.csv)\n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        file_path = self.path + self.csv['Filename'].values[idx]\n",
    "        image = self.load_img(file_path)\n",
    "                \n",
    "        if (self.transform == 1):\n",
    "            rand = np.random.randint(0, 4, 1)\n",
    "                \n",
    "            image = self.transformation(image, rand)\n",
    "\n",
    "        image = zoom(image, (96/image.shape[0], 96/image.shape[1], 96/image.shape[2]))\n",
    "        image = self.normalize(image)\n",
    "        \n",
    "        if (self.task == 'disease'):\n",
    "\n",
    "                    \n",
    "            if (self.csv['Group'].values[idx] == 'CN'):\n",
    "                label = 0\n",
    "            elif (self.csv['Group'].values[idx] == 'AD'):\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 1\n",
    "        elif (self.task == 'race'):\n",
    "            \n",
    "            if (self.csv['Race'].values[idx] == 0):\n",
    "                label = 0\n",
    "            elif (self.csv['Race'].values[idx] != 0):\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 1\n",
    "                \n",
    "        elif (self.task == 'age'):\n",
    "            \n",
    "            if (self.csv['Age'].values[idx] <= 75):\n",
    "                label = 0\n",
    "            elif (self.csv['Age'].values[idx] > 75):\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 1\n",
    "                \n",
    "        elif (self.task == 'sex'):\n",
    "            \n",
    "            if (self.csv['Sex'].values[idx] == 'F'):\n",
    "                label = 0\n",
    "            elif (self.csv['Sex'].values[idx] == 'M'):\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 1\n",
    "                \n",
    "        else:\n",
    "            print('Wrong task!')\n",
    "            \n",
    "            return \n",
    "        \n",
    "        demo = torch.tensor([0 if self.csv['Sex'].values[idx] == 'F' else 1,\n",
    "                             0 if self.csv['Age'].values[idx] <= 75 else 1])\n",
    "\n",
    "        image = torch.unsqueeze(torch.from_numpy(image), 0)\n",
    "        label = torch.tensor(label)\n",
    "                       \n",
    "        return image, label, demo\n",
    "    \n",
    "    def load_img(self, file_path):\n",
    "        data = nib.load(file_path)\n",
    "        data = np.array(data.dataobj)\n",
    "        return data\n",
    "    \n",
    "    def normalize(self, arr):\n",
    "        arr_min = np.min(arr)\n",
    "        arr_max = np.max(arr)\n",
    "        return (arr - arr_min) / (arr_max - arr_min)\n",
    "    \n",
    "    def transformation(self, img, rand):\n",
    "    \n",
    "        img_np = np.copy(img)\n",
    "\n",
    "        if (rand == 0):\n",
    "            img_np = shear(img_np, 6)\n",
    "        elif (rand == 1):\n",
    "            img_np = scale(img_np, 0.8)\n",
    "        elif (rand == 2):\n",
    "            img_np = fish(img_np, 0.4)\n",
    "        else:\n",
    "            img_np = rotation(img_np, 10)\n",
    "            \n",
    "            \n",
    "        return img_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wrong-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(path, loss, auc, name):\n",
    "    f = open(path, 'a')\n",
    "    print('[%s] test_loss: %.3f // test_auc: %.3f ' % (name, loss, auc), file=f)                                                                          \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daily-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, df, data_path, model_path, epochs, transform, task, algo):\n",
    "    \n",
    "    num_worker = 16\n",
    "    Val_Data_set = ADNI_3D_Dataset(csv = df.loc[df['Split']=='val'], path = data_path, transform = transform, task = task)\n",
    "    Train_Data_set = ADNI_3D_Dataset(csv = df.loc[df['Split']=='train'], path = data_path, transform = transform, task = task)\n",
    "\n",
    "    val_dataloader = DataLoader(Val_Data_set, batch_size = batch_size, shuffle = True, num_workers = num_worker)\n",
    "    train_dataloader = DataLoader(Train_Data_set, batch_size = batch_size, shuffle = True, num_workers = num_worker)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    best_val_loss = float(\"Inf\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        if (algo == 'FairALM'):\n",
    "            lag_mult_r = torch.zeros(len(group_type['race']) * len(surrogate_fns))\n",
    "            lag_mult_g = torch.zeros(len(group_type['gender']) * len(surrogate_fns))\n",
    "            lag_mult_a = torch.zeros(len(group_type['age']) * len(surrogate_fns))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        model.train()\n",
    "        training_loss = 0.0 \n",
    "        train_accuracy = 0.0\n",
    "        loop = tqdm(enumerate(train_dataloader), total =len(train_dataloader))\n",
    "        for step, data in loop:     \n",
    "            inputs, labels, demo = data\n",
    "            inputs, labels, demo = inputs.to(device), labels.to(device), demo.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if (algo != 'Adv'):\n",
    "                outputs = torch.reshape(model(inputs), (len(labels),))\n",
    "            else:\n",
    "                all_outputs = model(inputs)\n",
    "                outputs_gender = torch.reshape(all_outputs[0], (len(labels), ))\n",
    "                outputs_age = torch.reshape(all_outputs[1], (len(labels), ))\n",
    "                outputs_disease = torch.reshape(all_outputs[2], (len(labels), ))\n",
    "                \n",
    "            if (algo == 'ERM'):\n",
    "                loss_value = ERM_Loss(labels.float(), outputs)\n",
    "            elif (algo == 'Adv'):\n",
    "                loss_value_gender = reciprocal_BCE_loss(demo[:, 0].float(), outputs_gender)\n",
    "                loss_value_age = reciprocal_BCE_loss(demo[:, 1].float(), outputs_age)\n",
    "                loss_value_disease = ERM_Loss(labels.float(), outputs_disease)\n",
    "                loss_value = loss_value_gender + loss_value_age + loss_value_disease\n",
    "            elif (algo == 'DistMatch'):\n",
    "                loss_value, penalty_g = DistMatch_Loss(labels.float(), outputs, demo[:, 0].float(), mode, 'gender')\n",
    "                loss_value, penalty_a = DistMatch_Loss(labels.float(), outputs, demo[:, 1].float(), mode, 'age')\n",
    "                loss_value = (loss_value + penalty_g + penalty_a)\n",
    "            elif (algo == 'FairALM'):\n",
    "                loss_value, penalty_g, lag_mult_g = fairALM_loss(labels.float(), outputs, demo[:, 0].float(), lag_mult_g, 'gender', False)\n",
    "                loss_value, penalty_a, lag_mult_a = fairALM_loss(labels.float(), outputs, demo[:, 1].float(), lag_mult_a, 'age', False)\n",
    "                loss_value += (loss_value + penalty_g + penalty_a)\n",
    "            else:\n",
    "                print('Wrong algo!')\n",
    "                break\n",
    "                \n",
    "            weight = torch.ones_like(loss_value)\n",
    "            weight[labels==1.] = weights[1]\n",
    "            loss = (loss_value * weight).mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            training_loss += loss.item()\n",
    "    \n",
    "            loop.set_description(f'Training epoch [{epoch}/80]')\n",
    "            loop.set_postfix(loss = training_loss/(step+1))\n",
    "\n",
    "        scheduler.step()\n",
    "        train_losses.append(training_loss/len(train_dataloader))\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        valid_accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "            loop = tqdm(enumerate(val_dataloader), total =len(val_dataloader))\n",
    "            for step, data in loop:\n",
    "                inputs, labels, demo = data\n",
    "                inputs, labels, demo = inputs.to(device), labels.to(device), demo.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if (algo != 'Adv'):\n",
    "                    outputs = torch.reshape(model(inputs), (len(labels),))\n",
    "                else:\n",
    "                    all_outputs = model(inputs)\n",
    "                    outputs_gender = torch.reshape(all_outputs[0], (len(labels), ))\n",
    "                    outputs_age = torch.reshape(all_outputs[1], (len(labels), ))\n",
    "                    outputs_disease = torch.reshape(all_outputs[2], (len(labels), ))\n",
    "\n",
    "                if (algo == 'ERM'):\n",
    "                    loss_value = ERM_Loss(labels.float(), outputs)\n",
    "                elif (algo == 'Adv'):\n",
    "                    loss_value_gender = reciprocal_BCE_loss(demo[:, 0].float(), outputs_gender)\n",
    "                    loss_value_age = reciprocal_BCE_loss(demo[:, 1].float(), outputs_age)\n",
    "                    loss_value_disease = ERM_Loss(labels.float(), outputs_disease)\n",
    "                    loss_value = loss_value_gender + loss_value_age + loss_value_disease\n",
    "                elif (algo == 'DistMatch'):\n",
    "                    loss_value, penalty_g = DistMatch_Loss(labels.float(), outputs, demo[:, 0].float(), mode, 'gender')\n",
    "                    loss_value, penalty_a = DistMatch_Loss(labels.float(), outputs, demo[:, 1].float(), mode, 'age')\n",
    "                    loss_value = (loss_value + penalty_g + penalty_a)\n",
    "                elif (algo == 'FairALM'):\n",
    "                    loss_value, penalty_g, lag_mult_g = fairALM_loss(labels.float(), outputs, demo[:, 0].float(), lag_mult_g, 'gender', False)\n",
    "                    loss_value, penalty_a, lag_mult_a = fairALM_loss(labels.float(), outputs, demo[:, 1].float(), lag_mult_a, 'age', False)\n",
    "                    loss_value += (loss_value + penalty_g + penalty_a)\n",
    "                else:\n",
    "                    print('Wrong algo!')\n",
    "                    break\n",
    "\n",
    "                weight = torch.ones_like(loss_value)\n",
    "                weight[labels==1.] = weights[1]\n",
    "                loss = (loss_value * weight).mean()\n",
    "\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                loop.set_description(f'Validataion epoch [{epoch}/80]')\n",
    "                loop.set_postfix(loss = valid_loss/(step+1))\n",
    "\n",
    "        val_losses.append(valid_loss / len(val_dataloader))\n",
    "        if(np.around(valid_loss/len(val_dataloader), 3) < np.around(best_val_loss, 3)):\n",
    "            count = 0\n",
    "            best_val_loss = valid_loss/len(val_dataloader)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"=========save model=========\")\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        if (count > 10):\n",
    "            print(\"=========Early stopping=========\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "communist-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fper, tper):\n",
    "    plt.plot(fper, tper, color='red', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='green', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def eval_step(model, df, data_path, model_path, val, transform, task):\n",
    "    \n",
    "    num_worker = 1\n",
    "    if (val):\n",
    "        split = 'val'\n",
    "        Data_set = ADNI_3D_Dataset(csv = df.loc[df['Split']==split], path = data_path, transform = transform, task = task)\n",
    "        dataloader = DataLoader(Data_set, batch_size = batch_size, shuffle = False, num_workers = num_worker)\n",
    "\n",
    "    else:\n",
    "        split = 'test'\n",
    "        Data_set = ADNI_3D_Dataset(csv = df.loc[df['Split']==split], path = data_path, transform = 0, task = task)\n",
    "        dataloader = DataLoader(Data_set, batch_size = batch_size, shuffle = False, num_workers = num_worker)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    target=[]\n",
    "    prob=[]\n",
    "    \n",
    "    if (algo == 'FairALM'):\n",
    "        lag_mult_r = torch.zeros(len(group_type['race']) * len(surrogate_fns))\n",
    "        lag_mult_g = torch.zeros(len(group_type['gender']) * len(surrogate_fns))\n",
    "        lag_mult_a = torch.zeros(len(group_type['age']) * len(surrogate_fns))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(enumerate(dataloader), total =len(dataloader))\n",
    "        for step, data in loop:\n",
    "            inputs, labels, demo = data\n",
    "            inputs, labels, demo = inputs.to(device), labels.to(device), demo.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if (algo != 'Adv'):\n",
    "                outputs = torch.reshape(model(inputs), (len(labels),))\n",
    "            else:\n",
    "                all_outputs = model(inputs)\n",
    "                outputs_gender = torch.reshape(all_outputs[0], (len(labels), ))\n",
    "                outputs_age = torch.reshape(all_outputs[1], (len(labels), ))\n",
    "                outputs_disease = torch.reshape(all_outputs[2], (len(labels), ))\n",
    "\n",
    "            if (algo == 'ERM'):\n",
    "                loss_value = ERM_Loss(labels.float(), outputs)\n",
    "            elif (algo == 'Adv'):\n",
    "                loss_value_gender = reciprocal_BCE_loss(demo[:, 0].float(), outputs_gender)\n",
    "                loss_value_age = reciprocal_BCE_loss(demo[:, 1].float(), outputs_age)\n",
    "                loss_value_disease = ERM_Loss(labels.float(), outputs_disease)\n",
    "                loss_value = loss_value_gender + loss_value_age + loss_value_disease\n",
    "            elif (algo == 'DistMatch'):\n",
    "                loss_value, penalty_g = DistMatch_Loss(labels.float(), outputs, demo[:, 0].float(), mode, 'gender')\n",
    "                loss_value, penalty_a = DistMatch_Loss(labels.float(), outputs, demo[:, 1].float(), mode, 'age')\n",
    "                loss_value = (loss_value + penalty_g + penalty_a)\n",
    "            elif (algo == 'FairALM'):\n",
    "                loss_value, penalty_g, lag_mult_g = fairALM_loss(labels.float(), outputs, demo[:, 0].float(), lag_mult_g, 'gender', False)\n",
    "                loss_value, penalty_a, lag_mult_a = fairALM_loss(labels.float(), outputs, demo[:, 1].float(), lag_mult_a, 'age', False)\n",
    "                loss_value += (loss_value + penalty_g + penalty_a)\n",
    "            else:\n",
    "                print('Wrong algo!')\n",
    "                break\n",
    "\n",
    "            weight = torch.ones_like(loss_value)\n",
    "            weight[labels==1.] = weights[1]\n",
    "            loss = (loss_value * weight).mean()\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            target.extend(np.array(labels.cpu()))\n",
    "            \n",
    "            if (algo != 'Adv'):\n",
    "                prob.extend(outputs.detach().cpu().numpy())\n",
    "            else:\n",
    "                prob.extend(outputs_disease.detach().cpu().numpy())\n",
    "\n",
    "            loop.set_description(f'Test epoch')\n",
    "            loop.set_postfix(step=(step+1), loss = test_loss/(step+1))\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(target, prob)\n",
    "    auc_curve = auc(fpr, tpr)\n",
    "    print(\"AUC: \", auc_curve)\n",
    "    \n",
    "    if (val):\n",
    "        best_thresh = cal_best_thresh(np.array(target), np.array(prob))\n",
    "\n",
    "        np.savetxt('thresh/{i}_thresh.txt'.format(i=model_path[12:-4]), [best_thresh])\n",
    "    else:\n",
    "        with open('predictions/'+model_path[12:-4]+'_on_original', \"wb\") as fp:\n",
    "            pickle.dump(np.array(prob), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "useful-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, df, data_path, split):\n",
    "    \n",
    "    X_embeddings = []\n",
    "    \n",
    "    Data_set = ADNI_3D_Dataset(csv = df.loc[df['Split']==split], path = data_path, transform = 0, task = 'disease')\n",
    "    dataloader = DataLoader(Data_set, batch_size = 1, shuffle = False, num_workers = 16)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(enumerate(dataloader), total =len(dataloader))\n",
    "        for step, data in loop:\n",
    "            inputs, labels, demo = data\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            X_embeddings.append(outputs.numpy()[0])\n",
    "            \n",
    "    \n",
    "    return X_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fatal-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_best_thresh(y_test, y_preds):\n",
    "    best_thresh = 0\n",
    "    best = 0\n",
    "    tprs, fprs, threshes = get_threshes(y_test, y_preds)\n",
    "        \n",
    "    for i in range(len(threshes)):\n",
    "        score = f1_score(y_test, np.where(y_preds >= threshes[i], 1, 0), average='binary')\n",
    "        if (score > best):\n",
    "            best = score\n",
    "            best_thresh = threshes[i]\n",
    "                \n",
    "    return best_thresh\n",
    "\n",
    "def get_threshes(y_test, preds):\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(y_test, preds, drop_intermediate=False)\n",
    "        \n",
    "    return tpr, fpr, threshold\n",
    "\n",
    "def get_tpr(y_test, preds, thresh):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, np.where(preds >= thresh, 1, 0)).ravel()\n",
    "    \n",
    "    return tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "recent-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7956, 1.3457])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_new.csv')\n",
    "data_path = '../../../mnt/usb/kuopc/ADNI_B1/MPR__GradWarp__B1_Correction_crop/'\n",
    "\n",
    "df = df.loc[df['Group'] != 'MCI']\n",
    "\n",
    "\n",
    "# class_0 = len(np.where(df['Age'] <= 75)[0])\n",
    "# class_1 = len(np.where(df['Age'] > 75)[0])\n",
    "\n",
    "# class_0 = len(np.where(df['Sex'] == 'F')[0])\n",
    "# class_1 = len(np.where(df['Sex'] == 'M')[0])\n",
    "\n",
    "class_0 = len(np.where(df['Group'] == 'CN')[0])\n",
    "class_1 = len(np.where(df['Group'] == 'AD')[0])\n",
    "\n",
    "total = class_0 + class_1\n",
    "\n",
    "weight_for_0 = (1 / class_0) * (total / 2.0)\n",
    "weight_for_1 = (1 / class_1) * (total / 2.0)\n",
    "\n",
    "weights = torch.tensor([weight_for_0, weight_for_1], dtype=torch.float32)\n",
    "\n",
    "print(weights)\n",
    "print(type(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "south-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(file_path):\n",
    "    data = nib.load(file_path)\n",
    "    data = np.array(data.dataobj)\n",
    "    return data\n",
    "\n",
    "def normalize(arr):\n",
    "    arr_min = np.min(arr)\n",
    "    arr_max = np.max(arr)\n",
    "    return (arr - arr_min) / (arr_max - arr_min)\n",
    "\n",
    "with torch.no_grad():\n",
    "    def compute_aug_predictions(model, model_path, df, data_path):\n",
    "        seed = 2021\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        y_preds = []\n",
    "\n",
    "        loop = tqdm(enumerate(df['Filename']), total =len(df['Filename']))\n",
    "        for i, file in loop:\n",
    "\n",
    "            file_path = data_path + file\n",
    "            image = load_img(file_path)\n",
    "\n",
    "            aug_inputs = []\n",
    "            for _ in range(3):\n",
    "\n",
    "                try:\n",
    "                    aug_img = shear(image, 6)\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "                except:\n",
    "                    aug_img = image\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "\n",
    "                try:\n",
    "                    aug_img = rotation(image, 10)\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "                except:\n",
    "                    aug_img = image\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "\n",
    "                try:\n",
    "                    aug_img = fish(image, 0.4)\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "                except:\n",
    "                    aug_img = image\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "\n",
    "                try:\n",
    "                    aug_img = scale(image, 0.8)\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "                except:\n",
    "                    aug_img = image\n",
    "                    aug_inputs.append(normalize(zoom(aug_img, (96/aug_img.shape[0], 96/aug_img.shape[1], 96/aug_img.shape[2]))))\n",
    "\n",
    "                del aug_img\n",
    "                gc.collect()\n",
    "\n",
    "            aug_inputs = torch.unsqueeze(torch.from_numpy(np.array(aug_inputs)), 1).to(device)\n",
    "\n",
    "            temp_predict = model(aug_inputs)\n",
    "\n",
    "            y_preds.append(torch.mean(temp_predict))\n",
    "\n",
    "            del aug_inputs, image, temp_predict\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            print(i)\n",
    "\n",
    "\n",
    "        with open('predictions/'+model_path[12:-4]+'_on_aug', \"wb\") as fp:\n",
    "            pickle.dump(np.array(y_preds), fp)\n",
    "        fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "advisory-cassette",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_shape = (1, 96, 96, 96)\n",
    "batch_size = 16\n",
    "\n",
    "np.random.seed(2021)\n",
    "torch.manual_seed(2021)\n",
    "\n",
    "epochs = 80\n",
    "\n",
    "model_path = 'checkpoints/3D_CNN_AD_CN_proposed.pth'\n",
    "\n",
    "model = resnet3d_model(18, adv=False)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if not ('layer4' in name):\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        break\n",
    "#         param.requires_grad = True\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "demanding-nurse",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1       [-1, 64, 96, 48, 48]          21,952\n",
      "       BatchNorm3d-2       [-1, 64, 96, 48, 48]             128\n",
      "              ReLU-3       [-1, 64, 96, 48, 48]               0\n",
      "         MaxPool3d-4       [-1, 64, 48, 24, 24]               0\n",
      "            Conv3d-5       [-1, 64, 48, 24, 24]         110,592\n",
      "       BatchNorm3d-6       [-1, 64, 48, 24, 24]             128\n",
      "              ReLU-7       [-1, 64, 48, 24, 24]               0\n",
      "            Conv3d-8       [-1, 64, 48, 24, 24]         110,592\n",
      "       BatchNorm3d-9       [-1, 64, 48, 24, 24]             128\n",
      "             ReLU-10       [-1, 64, 48, 24, 24]               0\n",
      "       BasicBlock-11       [-1, 64, 48, 24, 24]               0\n",
      "           Conv3d-12       [-1, 64, 48, 24, 24]         110,592\n",
      "      BatchNorm3d-13       [-1, 64, 48, 24, 24]             128\n",
      "             ReLU-14       [-1, 64, 48, 24, 24]               0\n",
      "           Conv3d-15       [-1, 64, 48, 24, 24]         110,592\n",
      "      BatchNorm3d-16       [-1, 64, 48, 24, 24]             128\n",
      "             ReLU-17       [-1, 64, 48, 24, 24]               0\n",
      "       BasicBlock-18       [-1, 64, 48, 24, 24]               0\n",
      "           Conv3d-19      [-1, 128, 24, 12, 12]         221,184\n",
      "      BatchNorm3d-20      [-1, 128, 24, 12, 12]             256\n",
      "             ReLU-21      [-1, 128, 24, 12, 12]               0\n",
      "           Conv3d-22      [-1, 128, 24, 12, 12]         442,368\n",
      "      BatchNorm3d-23      [-1, 128, 24, 12, 12]             256\n",
      "           Conv3d-24      [-1, 128, 24, 12, 12]           8,192\n",
      "      BatchNorm3d-25      [-1, 128, 24, 12, 12]             256\n",
      "             ReLU-26      [-1, 128, 24, 12, 12]               0\n",
      "       BasicBlock-27      [-1, 128, 24, 12, 12]               0\n",
      "           Conv3d-28      [-1, 128, 24, 12, 12]         442,368\n",
      "      BatchNorm3d-29      [-1, 128, 24, 12, 12]             256\n",
      "             ReLU-30      [-1, 128, 24, 12, 12]               0\n",
      "           Conv3d-31      [-1, 128, 24, 12, 12]         442,368\n",
      "      BatchNorm3d-32      [-1, 128, 24, 12, 12]             256\n",
      "             ReLU-33      [-1, 128, 24, 12, 12]               0\n",
      "       BasicBlock-34      [-1, 128, 24, 12, 12]               0\n",
      "           Conv3d-35        [-1, 256, 12, 6, 6]         884,736\n",
      "      BatchNorm3d-36        [-1, 256, 12, 6, 6]             512\n",
      "             ReLU-37        [-1, 256, 12, 6, 6]               0\n",
      "           Conv3d-38        [-1, 256, 12, 6, 6]       1,769,472\n",
      "      BatchNorm3d-39        [-1, 256, 12, 6, 6]             512\n",
      "           Conv3d-40        [-1, 256, 12, 6, 6]          32,768\n",
      "      BatchNorm3d-41        [-1, 256, 12, 6, 6]             512\n",
      "             ReLU-42        [-1, 256, 12, 6, 6]               0\n",
      "       BasicBlock-43        [-1, 256, 12, 6, 6]               0\n",
      "           Conv3d-44        [-1, 256, 12, 6, 6]       1,769,472\n",
      "      BatchNorm3d-45        [-1, 256, 12, 6, 6]             512\n",
      "             ReLU-46        [-1, 256, 12, 6, 6]               0\n",
      "           Conv3d-47        [-1, 256, 12, 6, 6]       1,769,472\n",
      "      BatchNorm3d-48        [-1, 256, 12, 6, 6]             512\n",
      "             ReLU-49        [-1, 256, 12, 6, 6]               0\n",
      "       BasicBlock-50        [-1, 256, 12, 6, 6]               0\n",
      "           Conv3d-51         [-1, 512, 6, 3, 3]       3,538,944\n",
      "      BatchNorm3d-52         [-1, 512, 6, 3, 3]           1,024\n",
      "             ReLU-53         [-1, 512, 6, 3, 3]               0\n",
      "           Conv3d-54         [-1, 512, 6, 3, 3]       7,077,888\n",
      "      BatchNorm3d-55         [-1, 512, 6, 3, 3]           1,024\n",
      "           Conv3d-56         [-1, 512, 6, 3, 3]         131,072\n",
      "      BatchNorm3d-57         [-1, 512, 6, 3, 3]           1,024\n",
      "             ReLU-58         [-1, 512, 6, 3, 3]               0\n",
      "       BasicBlock-59         [-1, 512, 6, 3, 3]               0\n",
      "           Conv3d-60         [-1, 512, 6, 3, 3]       7,077,888\n",
      "      BatchNorm3d-61         [-1, 512, 6, 3, 3]           1,024\n",
      "             ReLU-62         [-1, 512, 6, 3, 3]               0\n",
      "           Conv3d-63         [-1, 512, 6, 3, 3]       7,077,888\n",
      "      BatchNorm3d-64         [-1, 512, 6, 3, 3]           1,024\n",
      "             ReLU-65         [-1, 512, 6, 3, 3]               0\n",
      "       BasicBlock-66         [-1, 512, 6, 3, 3]               0\n",
      "AdaptiveAvgPool3d-67         [-1, 512, 1, 1, 1]               0\n",
      "           Linear-68                    [-1, 1]             513\n",
      "          Sigmoid-69                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 33,160,513\n",
      "Trainable params: 24,909,313\n",
      "Non-trainable params: 8,251,200\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.38\n",
      "Forward/backward pass size (MB): 597.38\n",
      "Params size (MB): 126.50\n",
      "Estimated Total Size (MB): 727.25\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (1, 96, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "immune-permission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f83d9de70a485e881d95d5ddb9dffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2863842fabd47da8ece3516eefc9de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========save model=========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739ddce5637045f2b7443d5df5b543d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e51f73ebbe74b1391b6d4a7689c939f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========save model=========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ece42bfc1540e487ed4be053a5fcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099e158d7cc242cf848c297f2bb6cecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========save model=========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132a60f34c0c489cbb7039e6961213e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df85a79deb5046f49687b11cf9314911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========save model=========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca19d2d270642099548ad597245c456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ad265d1e444b37b9e7657e2d25aa97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========save model=========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c228bbec7934539b72a074232f96700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a489112b37407ba099de7fa637b463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ab9e123a244783adaabe9fe77d4e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b578be28cecb431494c667c722638316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c009fc69a5e4606b458d496e6365d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dedcd8c7e07b423e932e24c1d2d18ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========save model=========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a33a7e204b440b1ac80e29df6dfd707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a95e8405a57403b96283891d0f050d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866f6c76d6814345a763d1fe45ab3167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685b6f41aff045d7925ff08fe6d0fbe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa8bc1080d94f769bc9c2aaf779cc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fe82b0222b4fb9b17c067b14aba87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192a44bf42514d89adef0fcfc5c43831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f861f5049ecf4c9faed5ed253823a99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b9c60ecae94d5b84b81cd011ffee96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c54b84fd41041c399834fcccad26171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae4f72a8bcb44eebd4109c047bb6638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d018ac0bb66465b8b08f299c4202d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e939b4bfd2f40b9a58d358135b23633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8f1e2b305c46b5b466bc8b4552e84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e5d0d98c644f53b7079dc8f9b26759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3b30d403da446c8ca41ae28c10c8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d3b10247814eb09eae64b61de53c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734e4b7b0c974a0fa6f7f6a625fc3966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9827901ffc4449239048f6dd1022692d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ce78233680415784e0c59b78204c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Early stopping=========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add234201a704273a847351e59428bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6318002984669651\n"
     ]
    }
   ],
   "source": [
    "model_path = 'checkpoints/3D_CNN_AD_CN_proposed_task_transfer_age_2.pth'\n",
    "\n",
    "optimizer = Adam(model.parameters(),lr=1e-5, weight_decay=1e-6) \n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=60, gamma=0.1) \n",
    "\n",
    "task = 'age'\n",
    "algo = 'ERM'\n",
    "\n",
    "train_step(model, df, data_path, model_path,  epochs, 0, task, algo)\n",
    "# eval_step(model, df, data_path, model_path, True, 0, task)     calculate threshold, no needed for task transfer \n",
    "\n",
    "\n",
    "eval_step(model, df, data_path, model_path, False, 0, task)  # for original data\n",
    "\n",
    "# for aug. data\n",
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     compute_aug_predictions(model, model_path, df.loc[df['Split'] == 'test'], data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "floral-cattle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2a09bf618e47e9b824a3b95a126096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7331701346389227\n"
     ]
    }
   ],
   "source": [
    "# if just want to test\n",
    "\n",
    "model_path = 'checkpoints/3D_CNN_AD_CN_task_transfer_age_2.pth'\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "task = 'age'\n",
    "algo = 'ERM'\n",
    "\n",
    "model = resnet3d_model(18, adv=False)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(),lr=1e-5, weight_decay=1e-6) \n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=60, gamma=0.1) \n",
    "\n",
    "\n",
    "eval_step(model, df, data_path, model_path, False, 0, task)  # for original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "silent-state",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0715c7890214cbca24e0b57a3eedc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7690738474092207\n"
     ]
    }
   ],
   "source": [
    "# if just want to test\n",
    "\n",
    "model_path = 'checkpoints/3D_CNN_AD_CN_task_transfer_gender.pth'\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "task = 'sex'\n",
    "algo = 'ERM'\n",
    "\n",
    "model = resnet3d_model(18, adv=False)\n",
    "# model.fc = net()\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(),lr=1e-5, weight_decay=1e-6) \n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=60, gamma=0.1) \n",
    "\n",
    "\n",
    "eval_step(model, df, data_path, model_path, False, 0, task)  # for original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "selected-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_new.csv')\n",
    "data_path = '../../../mnt/usb/kuopc/ADNI_B1/MPR__GradWarp__B1_Correction_crop/'\n",
    "\n",
    "df = df.loc[df['Group'] != 'MCI']\n",
    "df = df.loc[df['Split'] == 'test']\n",
    "\n",
    "df['Group'] = df['Group'].replace(['CN', 'AD'], [0, 1])\n",
    "df['Sex'] = df['Sex'].replace(['F', 'M'], [0, 1])\n",
    "df['Age'] = np.where(df['Age'] <= 75, 0, 1)\n",
    "df['Race'] = np.where(df['Race'] < 1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-appreciation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_name = 'predictions/3D_CNN_AD_CN_task_transfer_gender_on_original'\n",
    "\n",
    "with open(file_name, \"rb\") as fp:\n",
    "    y_preds = CPU_Unpickler(fp).load()\n",
    "fp.close()\n",
    "\n",
    "all_mean_score, all_lower, all_upper = task_transfer_test(y_preds, df['Sex'].values)\n",
    "\n",
    "print(all_mean_score, all_lower, all_upper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "progressive-privacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5785567836623515 0.49534198934779367 0.6617715779769094\n"
     ]
    }
   ],
   "source": [
    "file_name = 'predictions/3D_CNN_AD_CN_proposed_task_transfer_gender_on_original'\n",
    "\n",
    "with open(file_name, \"rb\") as fp:\n",
    "    y_preds = CPU_Unpickler(fp).load()\n",
    "fp.close()\n",
    "\n",
    "all_mean_score, all_lower, all_upper = task_transfer_test(y_preds, df['Sex'].values)\n",
    "\n",
    "print(all_mean_score, all_lower, all_upper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "round-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (1, 96, 96, 96)\n",
    "batch_size = 16\n",
    "\n",
    "np.random.seed(2021)\n",
    "torch.manual_seed(2021)\n",
    "\n",
    "epochs = 80\n",
    "\n",
    "model_path = 'checkpoints/3D_CNN_AD_CN_proposed.pth'\n",
    "\n",
    "model = resnet3d_model(18, adv=False)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "# model.fc = net()\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if not ('fc' in name):\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "continental-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "model.fc = Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "described-documentary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4a3ceae7264fdfb3bbbbc830f57497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "X_embeddings = get_embeddings(model, df, data_path, 'train')\n",
    "# pca = decomposition.PCA(n_components=100, whiten=False, svd_solver='full')\n",
    "# X_embeds_pca = pca.fit_transform(X_embeddings)\n",
    "\n",
    "directory = 'embeddings/'\n",
    "with open(directory+'training_3dresnet_proposed_model', \"wb\") as fp:\n",
    "    pickle.dump(X_embeddings, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "decimal-unemployment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8196e22cd0470dbeeaee2fbf421c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.42356861145110836\n"
     ]
    }
   ],
   "source": [
    "# if just want to test\n",
    "\n",
    "model_path = 'checkpoints/3D_CNN_AD_CN_proposed_task_transfer_gender.pth'\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "task = 'sex'\n",
    "algo = 'ERM'\n",
    "\n",
    "model = resnet3d_model(18, adv=False)\n",
    "model.fc = net()\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(),lr=1e-5, weight_decay=1e-6) \n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=60, gamma=0.1) \n",
    "\n",
    "\n",
    "eval_step(model, df, data_path, model_path, False, 0, task)  # for original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vocational-regard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41013df07a784e078b95232f414162c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5083639330885353\n"
     ]
    }
   ],
   "source": [
    "# if just want to test\n",
    "\n",
    "model_path = 'checkpoints/3D_CNN_AD_CN_proposed_task_transfer_gender.pth'\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "task = 'sex'\n",
    "algo = 'ERM'\n",
    "\n",
    "model = resnet3d_model(18, adv=False)\n",
    "model.fc = net()\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(),lr=1e-5, weight_decay=1e-6) \n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=60, gamma=0.1) \n",
    "\n",
    "\n",
    "eval_step(model, df, data_path, model_path, False, 0, task)  # for original data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe5a9d7ed15783e8a7a59b50df3e0c454a9bbc278a1b7ec2a6ccdea2d04cfc00"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
