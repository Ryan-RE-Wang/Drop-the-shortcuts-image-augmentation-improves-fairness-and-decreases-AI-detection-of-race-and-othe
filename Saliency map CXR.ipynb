{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-quick",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform as st\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "import pickle\n",
    "from transformation import *\n",
    "from models import *\n",
    "from load_data import *\n",
    "from GradCAM_Salency_map import *\n",
    " \n",
    "print(tf.__version__)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "tf.config.set_visible_devices(devices=gpus[0], device_type='GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2021\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-physics",
   "metadata": {},
   "source": [
    "## Saliency map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels_diseases = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
    "group_name = {'race': ['white', 'black', 'asian'], 'gender': ['male', 'female'], 'age': ['0_40', '40_60', '60_80', '80+']}\n",
    "group_class = {'race': [0, 1, 2], 'gender': [0, 1], 'age': [0, 1, 2, 3]}\n",
    "target_label = [0, 1, 2, 3, 4, 7, 8, 9, 11, 12]\n",
    "\n",
    "def compute_smap(img, model):\n",
    "\n",
    "    image = tf.reshape(img, [1, 224, 224])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        loss = model(image, training=False)[0]\n",
    "                \n",
    "            \n",
    "    grads = tape.gradient(loss, image)\n",
    "\n",
    "    dgrad_max_ = tf.math.abs(grads)\n",
    "#     grads = grads[grads < 0] = 0\n",
    "\n",
    "#     arr_min, arr_max  = np.min(dgrad_max_), np.max(dgrad_max_)\n",
    "#     smap = (dgrad_max_ - arr_min) / (arr_max - arr_min + 1e-18)\n",
    "\n",
    "    smap = grads\n",
    "\n",
    "    gc.collect()\n",
    "        \n",
    "    return smap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, last_conv_layer_model, classifier_model, target_class=None):\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute activations of the last conv layer and make the tape watch it\n",
    "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "        # Compute class predictions\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        \n",
    "        if (target_class is not None):\n",
    "            top_pred_index = tf.constant(target_class)\n",
    "        else:\n",
    "            top_pred_index = tf.argmax(preds[0])\n",
    "        \n",
    "        top_class_channel = preds[:, top_pred_index]\n",
    "                \n",
    "    # This is the gradient of the top predicted class with regard to\n",
    "    # the output feature map of the last conv layer\n",
    "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
    "    \n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    # The channel-wise mean of the resulting feature map\n",
    "    # is our heatmap of class activation\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "def show_heatmap(img_array, last_conv_layer_model, classifier_model, target_class=None):\n",
    "\n",
    "    heatmap = make_gradcam_heatmap(img_array, last_conv_layer_model, classifier_model, target_class)\n",
    "\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # We use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # We create an image with RGB colorized heatmap\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((224, 224))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "        \n",
    "    return jet_heatmap\n",
    "\n",
    "def grad_cam_plus(img_array, last_conv_layer_model, classifier_model, target_class=None):\n",
    "    \"\"\"Get a heatmap by Grad-CAM++.\n",
    "    Args:\n",
    "        model: A model object, build from tf.keras 2.X.\n",
    "        img: An image ndarray.\n",
    "        layer_name: A string, layer name in model.\n",
    "        label_name: A list or None,\n",
    "            show the label name by assign this argument,\n",
    "            it should be a list of all label names.\n",
    "        category_id: An integer, index of the class.\n",
    "            Default is the category with the highest score in the prediction.\n",
    "    Return:\n",
    "        A heatmap ndarray(without color).\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.GradientTape() as gtape1:\n",
    "        with tf.GradientTape() as gtape2:\n",
    "            with tf.GradientTape() as gtape3:\n",
    "                last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "                # Compute class predictions\n",
    "                preds = classifier_model(last_conv_layer_output)\n",
    "\n",
    "                if (target_class is not None):\n",
    "                    top_pred_index = tf.constant(target_class)\n",
    "                else:\n",
    "                    top_pred_index = tf.argmax(preds[0])\n",
    "\n",
    "                top_class_channel = preds[:, top_pred_index]\n",
    "                \n",
    "            conv_first_grad = gtape3.gradient(top_class_channel, last_conv_layer_output)\n",
    "            \n",
    "        conv_second_grad = gtape2.gradient(conv_first_grad, last_conv_layer_output)\n",
    "        \n",
    "    conv_third_grad = gtape1.gradient(conv_second_grad, last_conv_layer_output)\n",
    "\n",
    "    global_sum = np.sum(last_conv_layer_output, axis=(0, 1, 2))\n",
    "\n",
    "    alpha_num = conv_second_grad[0]\n",
    "    alpha_denom = conv_second_grad[0]*2.0 + conv_third_grad[0]*global_sum\n",
    "    alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, 1e-10)\n",
    "\n",
    "    alphas = alpha_num/alpha_denom\n",
    "    alpha_normalization_constant = np.sum(alphas, axis=(0,1))\n",
    "    alpha_normalization_constant = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, 1)\n",
    "    alphas /= alpha_normalization_constant\n",
    "    \n",
    "    weights = np.maximum(conv_first_grad[0], 0.0)\n",
    "    \n",
    "    deep_linearization_weights = np.sum(weights*alphas, axis=(0,1))\n",
    "    grad_cam_map = np.sum(deep_linearization_weights*last_conv_layer_output[0], axis=2)\n",
    "    \n",
    "    arr_min, arr_max  = np.min(grad_cam_map), np.max(grad_cam_map)\n",
    "    heatmap = (grad_cam_map - arr_min) / (arr_max - arr_min + 1e-18)\n",
    "    \n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    \n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # We use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # We create an image with RGB colorized heatmap\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((224, 224))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    return jet_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mimic'\n",
    "task = 'disease'\n",
    "\n",
    "X_test, y_test, demo = get_data(aug_method='', dataset=dataset, data_split='test', task=task, return_demo=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-gates",
   "metadata": {},
   "source": [
    "## Extract valid CXR id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels_diseases = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
    "\n",
    "target_label = [0, 1, 2, 3, 4, 7, 8, 9, 11, 12]\n",
    "\n",
    "prediction_name = 'predictions/model_densenet_mimic_ERM_on_original'\n",
    "best_thresh_0 = np.loadtxt('thresh/model_densenet_mimic_ERM_thresh.txt')\n",
    "\n",
    "with open(prediction_name, \"rb\") as fp:\n",
    "    y_preds_0 = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "\n",
    "prediction_name = 'predictions/model_densenet_mimic_ERM_proposed_on_original'\n",
    "best_thresh_1 = np.loadtxt('thresh/model_densenet_mimic_ERM_proposed_thresh.txt')\n",
    "\n",
    "with open(prediction_name, \"rb\") as fp:\n",
    "    y_preds_1 = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "for demo_idx, demo_group in enumerate(['race', 'gender', 'age']):\n",
    "    prediction_name = 'predictions/model_densenet_mimic_ERM_{demo_group}_on_original'.format(demo_group=demo_group)\n",
    "\n",
    "    with open(prediction_name, \"rb\") as fp:\n",
    "        y_preds_0_demo = pickle.load(fp)\n",
    "    fp.close()\n",
    "\n",
    "    prediction_name = 'predictions/model_densenet_mimic_ERM_{demo_group}_proposed_on_original'.format(demo_group=demo_group)\n",
    "\n",
    "    with open(prediction_name, \"rb\") as fp:\n",
    "        y_preds_1_demo = pickle.load(fp)\n",
    "    fp.close()\n",
    "\n",
    "    indice = []\n",
    "    demo_criteria = []\n",
    "    for i in range(len(group_class[demo_group])):\n",
    "        demo_criteria.append(np.percentile(y_preds_0_demo[:, i], 90))\n",
    "        \n",
    "    for i in range(len(y_preds_0)):\n",
    "        \n",
    "        cond_a = (np.argmax(y_preds_0_demo[i]) == demo[i][demo_idx] and y_preds_0_demo[i][np.argmax(y_preds_0_demo[i])] >= demo_criteria[np.argmax(y_preds_0_demo[i])])\n",
    "        cond_b = (np.argmax(y_preds_1_demo[i]) != demo[i][demo_idx])\n",
    "        if (cond_a and cond_b):\n",
    "            indice.append(i)\n",
    "\n",
    "    indice = np.array(indice)\n",
    "    \n",
    "    for label_idx in target_label:\n",
    "    \n",
    "        directory = 'imgs/{label}/'.format(label=Labels_diseases[label_idx])\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        valid_idx = []\n",
    "        for idx in indice:\n",
    "            if (y_test[idx][label_idx] == 1 and y_preds_0[idx][label_idx] > best_thresh_0[label_idx] and y_preds_1[idx][label_idx] > best_thresh_1[label_idx]):\n",
    "                valid_idx.append(idx)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        with open('imgs/{label}/{demo_group}_idx'.format(label=Labels_diseases[label_idx], demo_group=demo_group), \"wb\") as fp:\n",
    "            pickle.dump(np.array(valid_idx), fp)\n",
    "        fp.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels_diseases = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
    "\n",
    "target_label = [0, 1, 2, 3, 4, 7, 8, 9, 11, 12]\n",
    "\n",
    "prediction_name = 'predictions/model_densenet_mimic_ERM_on_original'\n",
    "best_thresh_0 = np.loadtxt('thresh/model_densenet_mimic_ERM_thresh.txt')\n",
    "\n",
    "with open(prediction_name, \"rb\") as fp:\n",
    "    y_preds_0 = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "\n",
    "prediction_name = 'predictions/model_densenet_mimic_ERM_proposed_on_original'\n",
    "best_thresh_1 = np.loadtxt('thresh/model_densenet_mimic_ERM_proposed_thresh.txt')\n",
    "\n",
    "with open(prediction_name, \"rb\") as fp:\n",
    "    y_preds_1 = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "for demo_idx, demo_group in enumerate(['race', 'gender', 'age']):\n",
    "    prediction_name = 'predictions/model_densenet_mimic_ERM_task_transfer_{demo_group}_on_original'.format(demo_group=demo_group)\n",
    "\n",
    "    with open(prediction_name, \"rb\") as fp:\n",
    "        y_preds_0_demo = pickle.load(fp)\n",
    "    fp.close()\n",
    "\n",
    "    prediction_name = 'predictions/model_densenet_mimic_ERM_task_transfer_{demo_group}_proposed_on_original'.format(demo_group=demo_group)\n",
    "\n",
    "    with open(prediction_name, \"rb\") as fp:\n",
    "        y_preds_1_demo = pickle.load(fp)\n",
    "    fp.close()\n",
    "\n",
    "    indice = []\n",
    "    demo_criteria = []\n",
    "    for i in range(len(group_class[demo_group])):\n",
    "        demo_criteria.append(np.percentile(y_preds_0_demo[:, i], 90))\n",
    "        \n",
    "    for i in range(len(y_preds_0)):\n",
    "        \n",
    "        cond_a = (np.argmax(y_preds_0_demo[i]) == demo[i][demo_idx] and y_preds_0_demo[i][np.argmax(y_preds_0_demo[i])] >= demo_criteria[np.argmax(y_preds_0_demo[i])])\n",
    "        cond_b = (np.argmax(y_preds_1_demo[i]) != demo[i][demo_idx])\n",
    "        if (cond_a and cond_b):\n",
    "            indice.append(i)\n",
    "\n",
    "    indice = np.array(indice)\n",
    "    \n",
    "    for label_idx in target_label:\n",
    "    \n",
    "        directory = 'imgs/{label}/'.format(label=Labels_diseases[label_idx])\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        valid_idx = []\n",
    "        for idx in indice:\n",
    "            if (y_test[idx][label_idx] == 1 and y_preds_0[idx][label_idx] > best_thresh_0[label_idx] and y_preds_1[idx][label_idx] > best_thresh_1[label_idx]):\n",
    "                valid_idx.append(idx)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        with open('imgs/{label}/task_transfer_{demo_group}_idx'.format(label=Labels_diseases[label_idx], demo_group=demo_group), \"wb\") as fp:\n",
    "            pickle.dump(np.array(valid_idx), fp)\n",
    "        fp.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-migration",
   "metadata": {},
   "source": [
    "## Compute saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_conv_model(model):\n",
    "    input_layer = model.get_layer(model.layers[0].name)\n",
    "    upsampling = model.get_layer(model.layers[1].name)\n",
    "    denset121 = model.get_layer(model.layers[2].name)\n",
    "\n",
    "    last_conv_layer_model = tf.keras.Sequential()\n",
    "    last_conv_layer_model.add(input_layer)\n",
    "    last_conv_layer_model.add(upsampling)\n",
    "    last_conv_layer_model.add(tf.keras.Model(denset121.inputs, denset121.layers[-4].output))\n",
    "    \n",
    "    # Second, we create a model that maps the activations of the last conv\n",
    "    # layer to the final class predictions\n",
    "    classifier_input = tf.keras.Input(shape=denset121.layers[-3].output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer in denset121.layers[-3:]:\n",
    "        x = denset121.get_layer(layer.name)(x)\n",
    "    x = model.get_layer(model.layers[-1].name)(x)\n",
    "    classifier_model = tf.keras.Model(classifier_input, x)   \n",
    "    \n",
    "    return last_conv_layer_model, classifier_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = [0, 1, 2, 3, 4, 7, 8, 9, 11, 12]\n",
    "    \n",
    "model_name = 'model_densenet_mimic_ERM'\n",
    "baseline_model = get_model('ERM', '', 'disease', 'densenet')\n",
    "checkpoint = tf.train.Checkpoint(baseline_model)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+model_name, max_to_keep=1, checkpoint_name=model_name)\n",
    "baseline_model.load_weights(manager.checkpoints[0])\n",
    "baseline_model_last_conv, baseline_model_classifier = get_last_conv_model(baseline_model)\n",
    "\n",
    "model_name = 'model_densenet_mimic_ERM_proposed'\n",
    "proposed_model = get_model('ERM', '', 'disease', 'densenet')\n",
    "checkpoint = tf.train.Checkpoint(proposed_model)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+model_name, max_to_keep=1, checkpoint_name=model_name)\n",
    "proposed_model.load_weights(manager.checkpoints[0])\n",
    "proposed_model_last_conv, proposed_model_classifier = get_last_conv_model(proposed_model)\n",
    "\n",
    "\n",
    "for label_idx in target_label:\n",
    "    \n",
    "    all_smap_baseline = []\n",
    "    all_smap_proposed = []\n",
    "    \n",
    "    directory = 'imgs/{label}/mean_map_gradcampp/disease/'.format(label=Labels_diseases[label_idx])\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    for demo_idx, group in enumerate(['race', 'gender', 'age']):\n",
    "\n",
    "        with open('imgs/{label}/{group}_idx'.format(label=Labels_diseases[label_idx], group=group), \"rb\") as fp:\n",
    "            indice = pickle.load(fp)\n",
    "        fp.close()\n",
    "\n",
    "        for idx in indice:\n",
    "\n",
    "#             smap = compute_smap(X_test[idx], baseline_model_last_conv)\n",
    "#             smap = show_heatmap(np.reshape(X_test[idx], (1, 224, 224, 1)), baseline_model_last_conv, baseline_model_classifier)\n",
    "            smap = grad_cam_plus(np.reshape(X_test[idx], (1, 224, 224, 1)), baseline_model_last_conv, baseline_model_classifier)\n",
    "            all_smap_baseline.append(smap)\n",
    "            \n",
    "\n",
    "#             smap = compute_smap(X_test[idx], proposed_model_last_conv)\n",
    "#             smap = show_heatmap(np.reshape(X_test[idx], (1, 224, 224, 1)), proposed_model_last_conv, proposed_model_classifier)\n",
    "            smap = grad_cam_plus(np.reshape(X_test[idx], (1, 224, 224, 1)), proposed_model_last_conv, proposed_model_classifier)\n",
    "            all_smap_proposed.append(smap)\n",
    "            \n",
    "    mean_smap_baseline = np.mean(all_smap_baseline, axis=0)\n",
    "    filename = 'imgs/{label}/mean_map_gradcampp/disease/baseline_model'.format(label=Labels_diseases[label_idx])\n",
    "    with open(filename, \"wb\") as fp:\n",
    "        pickle.dump(mean_smap_baseline, fp)\n",
    "    fp.close()\n",
    "\n",
    "    mean_smap_proposed = np.mean(all_smap_proposed, axis=0)\n",
    "    filename = 'imgs/{label}/mean_map_gradcampp/disease/proposed_model'.format(label=Labels_diseases[label_idx])\n",
    "    with open(filename, \"wb\") as fp:\n",
    "        pickle.dump(mean_smap_proposed, fp)\n",
    "    fp.close()\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = [0, 1, 2, 3, 4, 7, 8, 9, 11, 12]\n",
    "group_idx = {'race': 0, 'gender': 1, 'age': 2}\n",
    "\n",
    "for group in ['race', 'gender', 'age']:\n",
    "        \n",
    "    model_name = 'model_densenet_mimic_ERM_{group}'.format(group=group)\n",
    "    baseline_model = get_model('ERM', '', group, 'densenet')\n",
    "    checkpoint = tf.train.Checkpoint(baseline_model)\n",
    "    manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+model_name, max_to_keep=1, checkpoint_name=model_name)\n",
    "    baseline_model.load_weights(manager.checkpoints[0])\n",
    "    baseline_model = get_last_conv_model(baseline_model)\n",
    "    \n",
    "    model_name = 'model_densenet_mimic_ERM_{group}_proposed'.format(group=group)\n",
    "    proposed_model = get_model('ERM', '', group, 'densenet')\n",
    "    checkpoint = tf.train.Checkpoint(proposed_model)\n",
    "    manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+model_name, max_to_keep=1, checkpoint_name=model_name)\n",
    "    proposed_model.load_weights(manager.checkpoints[0])\n",
    "    proposed_model_last_conv, proposed_model_classifier = get_last_conv_model(proposed_model)\n",
    "\n",
    "\n",
    "    for label_idx in target_label:\n",
    "        \n",
    "        all_smap_baseline = []\n",
    "        all_smap_proposed = []\n",
    "        \n",
    "        directory = 'imgs/{label}/mean_map_gradcampp/{group}/'.format(label=Labels_diseases[label_idx], group=group)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        with open('imgs/{label}/{group}_idx'.format(label=Labels_diseases[label_idx], group=group), \"rb\") as fp:\n",
    "            indice = pickle.load(fp)\n",
    "        fp.close()\n",
    "\n",
    "        for idx in indice:\n",
    "\n",
    "#             smap = compute_smap(X_test[idx], baseline_model_last_conv)\n",
    "#             smap = show_heatmap(np.reshape(X_test[idx], (1, 224, 224, 1)), baseline_model_last_conv, baseline_model_classifier)\n",
    "            smap = grad_cam_plus(np.reshape(X_test[idx], (1, 224, 224, 1)), baseline_model_last_conv, baseline_model_classifier)\n",
    "            all_smap_baseline.append(smap)\n",
    "\n",
    "            \n",
    "#             smap = compute_smap(X_test[idx], proposed_model_last_conv)\n",
    "#             smap = show_heatmap(np.reshape(X_test[idx], (1, 224, 224, 1)), proposed_model_last_conv, proposed_model_classifier)\n",
    "            smap = grad_cam_plus(np.reshape(X_test[idx], (1, 224, 224, 1)), proposed_model_last_conv, proposed_model_classifier)\n",
    "            all_smap_proposed.append(smap)\n",
    "            \n",
    "        mean_smap_baseline = np.mean(all_smap_baseline, axis=0)\n",
    "        filename = 'imgs/{label}/mean_map_gradcampp/{group}/baseline_model_{group}'.format(label=Labels_diseases[label_idx], group=group)\n",
    "        with open(filename, \"wb\") as fp:\n",
    "            pickle.dump(mean_smap_baseline, fp)\n",
    "        fp.close()\n",
    "\n",
    "        mean_smap_proposed = np.mean(all_smap_proposed, axis=0)\n",
    "        filename = 'imgs/{label}/mean_map_gradcampp/{group}/proposed_model_{group}'.format(label=Labels_diseases[label_idx], group=group)\n",
    "        with open(filename, \"wb\") as fp:\n",
    "            pickle.dump(mean_smap_proposed, fp)\n",
    "        fp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = [0, 1, 2, 3, 4, 7, 8, 9, 11, 12]\n",
    "group_idx = {'race': 0, 'gender': 1, 'age': 2}\n",
    "\n",
    "for group in ['race', 'gender', 'age']:\n",
    "        \n",
    "    model_name = 'model_densenet_mimic_ERM_task_transfer_{group}'.format(group=group)\n",
    "    baseline_model = get_model('ERM', '', group, 'densenet')\n",
    "    checkpoint = tf.train.Checkpoint(baseline_model)\n",
    "    manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+model_name, max_to_keep=1, checkpoint_name=model_name)\n",
    "    baseline_model.load_weights(manager.checkpoints[0])\n",
    "    baseline_model_last_conv, baseline_model_classifier = get_last_conv_model(baseline_model)\n",
    "    \n",
    "    model_name = 'model_densenet_mimic_ERM_task_transfer_{group}_proposed'.format(group=group)\n",
    "    proposed_model = get_model('ERM', '', group, 'densenet')\n",
    "    checkpoint = tf.train.Checkpoint(proposed_model)\n",
    "    manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+model_name, max_to_keep=1, checkpoint_name=model_name)\n",
    "    proposed_model.load_weights(manager.checkpoints[0])\n",
    "    proposed_model = get_last_conv_model(proposed_model)\n",
    "\n",
    "\n",
    "    for label_idx in target_label:\n",
    "        directory = 'imgs/{label}/task_transfer_mean_map/{group}/'.format(label=Labels_diseases[label_idx], group=group)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        with open('imgs/{label}/task_transfer_{group}_idx'.format(label=Labels_diseases[label_idx], group=group), \"rb\") as fp:\n",
    "            indice = pickle.load(fp)\n",
    "        fp.close()\n",
    "\n",
    "        for idx in indice:\n",
    "\n",
    "            filename = 'imgs/{label}/task_transfer_mean_map/{group}/model_densenet_mimic_ERM_task_transfer_{group}_{idx}'.format(label=Labels_diseases[label_idx], group=group, model_name=model_name, idx=idx)\n",
    "\n",
    "            smap = compute_smap(X_test[idx], baseline_model, demo[idx][group_idx[group]])\n",
    "\n",
    "\n",
    "            with open(filename, \"wb\") as fp:\n",
    "                pickle.dump(smap, fp)\n",
    "            fp.close()\n",
    "            \n",
    "            \n",
    "            filename = 'imgs/{label}/task_transfer_mean_map/{group}/model_densenet_mimic_ERM_task_transfer_{group}_proposed_{idx}'.format(label=Labels_diseases[label_idx], group=group, model_name=model_name, idx=idx)\n",
    "\n",
    "            smap = compute_smap(X_test[idx], proposed_model, demo[idx][group_idx[group]])\n",
    "\n",
    "            with open(filename, \"wb\") as fp:\n",
    "                pickle.dump(smap, fp)\n",
    "            fp.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-constitutional",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mimic'\n",
    "task = 'disease'\n",
    "\n",
    "X_test, y_test, demo = get_data(aug_method='', dataset=dataset, data_split='test', task=task, return_demo=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(smap_1, smap_2, mean_img, label, demo_label, path):\n",
    "    plt.figure(figsize=(6, 4.5), dpi=300)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    \n",
    "    ax1 = plt.subplot(121)\n",
    "    ax1.axis('off')\n",
    "    ax1.imshow(mean_img, cmap='gray')\n",
    "    ax1.imshow(smap_1, cmap='Reds', alpha=0.3)\n",
    "    if (label == 'Enlarged Cardiomediastinum'):\n",
    "        ax1.set_title('Enlarged Card.'+ ' '+demo_label.capitalize()+' Baseline', fontsize=5)\n",
    "    else:\n",
    "        ax1.set_title(label+ ' '+demo_label.capitalize()+' Baseline', fontsize=5)\n",
    "    ax1.title.set_size(8)\n",
    "\n",
    "    ax2 = plt.subplot(122)\n",
    "    ax2.axis('off')\n",
    "    ax2.imshow(mean_img, cmap='gray')\n",
    "    ax2.imshow(smap_2, cmap='Reds', alpha=0.3)\n",
    "    if (label == 'Enlarged Cardiomediastinum'):\n",
    "        ax2.set_title('Enlarged Card.'+ ' '+demo_label.capitalize()+' Proposed', fontsize=5)\n",
    "    else:\n",
    "        ax2.set_title(label+ ' '+demo_label.capitalize()+' Proposed', fontsize=35)\n",
    "    ax2.title.set_size(8)\n",
    "    \n",
    "    \n",
    "    if not (os.path.exists(path)):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    plt.savefig(path+'{label}_{demo}.jpg'.format(label=label, demo=demo_label.capitalize()), bbox_inches='tight', transparent=\"True\")\n",
    "    plt.show() \n",
    "    \n",
    "    plt.figure(figsize=(6, 2), dpi=300)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    \n",
    "    counts, bins = np.histogram(smap_1, bins=100)\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax1.stairs(counts, bins, label='Baseline')\n",
    "    \n",
    "    counts, bins = np.histogram(smap_2, bins=100)\n",
    "    ax2 = plt.subplot(121)\n",
    "    ax2.stairs(counts, bins, label='Proposed')\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(path+'{label}_{demo}_histogram.jpg'.format(label=label, demo=demo_label.capitalize()), bbox_inches='tight', transparent=\"True\")\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels_diseases = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
    "target_label = [0, 1, 2, 3, 4, 7, 8, 9, 11, 12]\n",
    "group_name = {'race': ['white', 'black', 'asian'], 'gender': ['male', 'female'], 'age': ['0_40', '40_60', '60_80', '80+']}\n",
    "group_type = {'race': [0, 1, 4], 'gender': [0, 1], 'age': [0, 1, 2, 3]}\n",
    "\n",
    "all_img = []\n",
    "\n",
    "for label_idx in target_label:\n",
    "    \n",
    "    for group in ['race', 'age', 'gender']:\n",
    "        \n",
    "    \n",
    "        with open('imgs/{label}/{group}_idx'.format(label=Labels_diseases[label_idx], group=group), \"rb\") as fp:\n",
    "            ids = pickle.load(fp)\n",
    "        fp.close()\n",
    "        \n",
    "        for i, idx in enumerate(ids):\n",
    "            \n",
    "            img = X_test[idx]\n",
    "\n",
    "            all_img.append(img)\n",
    "        \n",
    "        with open('imgs/{label}/task_transfer_{group}_idx'.format(label=Labels_diseases[label_idx], group=group), \"rb\") as fp:\n",
    "            ids = pickle.load(fp)\n",
    "        fp.close()\n",
    "        \n",
    "        for i, idx in enumerate(ids):\n",
    "            \n",
    "            img = X_test[idx]\n",
    "\n",
    "            all_img.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_all_img = np.mean(all_img, axis=0)\n",
    "\n",
    "pixvals = np.copy(mean_all_img)\n",
    "\n",
    "minval = np.percentile(pixvals, 15)\n",
    "maxval = np.percentile(pixvals, 100)\n",
    "pixvals = np.clip(pixvals, minval, maxval)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(pixvals, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-teaching",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Labels_diseases = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
    "target_label = [0, 1, 2, 3, 4, 7, 8, 9, 11, 12]\n",
    "group_name = {'race': ['white', 'black', 'asian'], 'gender': ['male', 'female'], 'age': ['0_40', '40_60', '60_80', '80+']}\n",
    "group_type = {'race': [0, 1, 4], 'gender': [0, 1], 'age': [0, 1, 2, 3]}\n",
    "\n",
    "for group in ['race', 'age', 'gender']:\n",
    "    all_smap_baseline = []\n",
    "    all_smap_proposed = []\n",
    "    \n",
    "    for label_idx in target_label:\n",
    "                \n",
    "        with open('imgs/{label}/{group}_idx'.format(label=Labels_diseases[label_idx], group=group), \"rb\") as fp:\n",
    "            ids = pickle.load(fp)\n",
    "        fp.close()\n",
    "                \n",
    "        for i, idx in enumerate(ids):\n",
    "\n",
    "            directory = 'imgs/{label}/mean_map/{group}/model_densenet_mimic_ERM_{group}_{idx}'.format(label=Labels_diseases[label_idx], group=group, idx=idx, l=demo[idx][1])\n",
    "            with open(directory, \"rb\") as fp:\n",
    "                smap_baseline = pickle.load(fp)\n",
    "            fp.close()\n",
    "            \n",
    "            directory = 'imgs/{label}/mean_map/{group}/model_densenet_mimic_ERM_{group}_proposed_{idx}'.format(label=Labels_diseases[label_idx], group=group, idx=idx, l=demo[idx][1])\n",
    "            with open(directory, \"rb\") as fp:\n",
    "                smap_proposed = pickle.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            all_smap_baseline.append(np.abs(smap_baseline))\n",
    "            all_smap_proposed.append(np.abs(smap_proposed))\n",
    "            \n",
    "#             all_smap_baseline.append(np.clip(smap_baseline, 0, 1))\n",
    "#             all_smap_proposed.append(np.clip(smap_proposed, 0, 1))\n",
    "                        \n",
    "    mean_smap_baseline = np.mean(all_smap_baseline, axis=0)\n",
    "    mean_smap_proposed = np.mean(all_smap_proposed, axis=0)\n",
    "\n",
    "    maxval = np.max((np.max(mean_smap_baseline), np.max(mean_smap_proposed)))\n",
    "\n",
    "    mean_smap_baseline[0][0] = maxval\n",
    "    mean_smap_proposed[0][0] = maxval\n",
    "    \n",
    "    path = 'heatmaps/mean_map/'\n",
    "        \n",
    "    show(mean_smap_baseline, mean_smap_proposed, pixvals, 'All', group, path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels_diseases = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
    "target_label = [0, 1, 2, 3, 4, 7, 8, 9, 11, 12]\n",
    "group_name = {'race': ['white', 'black', 'asian'], 'gender': ['male', 'female'], 'age': ['0_40', '40_60', '60_80', '80+']}\n",
    "group_type = {'race': [0, 1, 4], 'gender': [0, 1], 'age': [0, 1, 2, 3]}\n",
    "\n",
    "for group in ['race', 'age', 'gender']:\n",
    "    all_smap_baseline = []\n",
    "    all_smap_proposed = []\n",
    "    \n",
    "    for label_idx in target_label:\n",
    "                \n",
    "        with open('imgs/{label}/task_transfer_{group}_idx'.format(label=Labels_diseases[label_idx], group=group), \"rb\") as fp:\n",
    "            ids = pickle.load(fp)\n",
    "        fp.close()\n",
    "                \n",
    "        for i, idx in enumerate(ids):\n",
    "\n",
    "            directory = 'imgs/{label}/task_transfer_mean_map/{group}/model_densenet_mimic_ERM_task_transfer_{group}_{idx}'.format(label=Labels_diseases[label_idx], group=group, idx=idx, l=demo[idx][1])\n",
    "            with open(directory, \"rb\") as fp:\n",
    "                smap_baseline = pickle.load(fp)\n",
    "            fp.close()\n",
    "            \n",
    "            directory = 'imgs/{label}/task_transfer_mean_map/{group}/model_densenet_mimic_ERM_task_transfer_{group}_proposed_{idx}'.format(label=Labels_diseases[label_idx], group=group, idx=idx, l=demo[idx][1])\n",
    "            with open(directory, \"rb\") as fp:\n",
    "                smap_proposed = pickle.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            all_smap_baseline.append(np.abs(smap_baseline))\n",
    "            all_smap_proposed.append(np.abs(smap_proposed))\n",
    "            \n",
    "#             all_smap_baseline.append(np.clip(smap_baseline, 0, 1))\n",
    "#             all_smap_proposed.append(np.clip(smap_proposed, 0, 1))\n",
    "                        \n",
    "    mean_smap_baseline = np.mean(all_smap_baseline, axis=0)\n",
    "    mean_smap_proposed = np.mean(all_smap_proposed, axis=0)\n",
    "\n",
    "    maxval = np.max((np.max(mean_smap_baseline), np.max(mean_smap_proposed)))\n",
    "\n",
    "    mean_smap_baseline[0][0] = maxval\n",
    "    mean_smap_proposed[0][0] = maxval\n",
    "    \n",
    "    path = 'heatmaps/task_transfer_mean_map/'\n",
    "        \n",
    "    show(mean_smap_baseline, mean_smap_proposed, pixvals, 'All', group, path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-works",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Labels_diseases = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
    "target_label = [0, 1, 2, 3, 4, 7, 8, 9, 11, 12]\n",
    "group_name = {'race': ['white', 'black', 'asian'], 'gender': ['male', 'female'], 'age': ['0_40', '40_60', '60_80', '80+']}\n",
    "group_type = {'race': [0, 1, 4], 'gender': [0, 1], 'age': [0, 1, 2, 3]}\n",
    "\n",
    "for label_idx in target_label:\n",
    "    \n",
    "    all_smap_baseline = []\n",
    "    all_smap_proposed = []\n",
    "    all_img = []\n",
    "    \n",
    "    for group in ['race', 'age', 'gender']:\n",
    "        \n",
    "        with open('imgs/{label}/{group}_idx'.format(label=Labels_diseases[label_idx], group=group), \"rb\") as fp:\n",
    "            ids = pickle.load(fp)\n",
    "        fp.close()\n",
    "    \n",
    "        for i, id in enumerate(ids):\n",
    "\n",
    "            with open('imgs/{label}/mean_map/{group}/model_densenet_mimic_ERM_{id}'.format(group=group, label=Labels_diseases[label_idx], id=id), \"rb\") as fp:\n",
    "                smap_baseline = pickle.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            with open('imgs/{label}/mean_map/{group}/model_densenet_mimic_ERM_proposed_{id}'.format(group=group, label=Labels_diseases[label_idx], id=id), \"rb\") as fp:\n",
    "                smap_proposed = pickle.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            img = X_test[id]\n",
    "\n",
    "            all_smap_baseline.append(np.abs(smap_baseline))\n",
    "            all_smap_proposed.append(np.abs(smap_proposed))\n",
    "            \n",
    "#             all_smap_baseline.append(np.clip(smap_baseline, 0, 1))\n",
    "#             all_smap_proposed.append(np.clip(smap_proposed, 0, 1))\n",
    "    \n",
    "    mean_smap_baseline = np.mean(all_smap_baseline, axis=0)\n",
    "    mean_smap_proposed = np.mean(all_smap_proposed, axis=0)\n",
    "    \n",
    "    maxval = np.max((np.max(mean_smap_baseline), np.max(mean_smap_proposed)))\n",
    "        \n",
    "    mean_smap_baseline[0][0] = maxval\n",
    "    mean_smap_proposed[0][0] = maxval\n",
    "    \n",
    "    path = 'heatmaps/mean_map/'\n",
    "\n",
    "    show(mean_smap_baseline, mean_smap_proposed, pixvals, Labels_diseases[label_idx], '', path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-reproduction",
   "metadata": {},
   "source": [
    "## Show individual heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset='mimic', label_type='No Finding'):\n",
    "    np.random.seed(2021)\n",
    "    \n",
    "    count_white = 0\n",
    "    count_black = 0\n",
    "    count_asian = 0\n",
    "        \n",
    "    X = []\n",
    "    y = []\n",
    "    demo = []\n",
    "    if (dataset == 'mimic'):\n",
    "        filename = 'data/mimic_test.tfrecords'\n",
    "    elif (dataset == 'chexpert'):\n",
    "        filename = '../Data/Chexpert_test.tfrecords'\n",
    "        \n",
    "    raw_dataset = tf.data.TFRecordDataset(filename)\n",
    "    for raw_record in raw_dataset:\n",
    "\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "                \n",
    "        nparr = np.fromstring(example.features.feature['jpg_bytes'].bytes_list.value[0], np.uint8)\n",
    "        img_np = cv.imdecode(nparr, cv.IMREAD_GRAYSCALE)  \n",
    "\n",
    "        if (example.features.feature[label_type].float_list.value[0] == 1):\n",
    "            X.append(tf.reshape(np.float32(st.resize(img_np, (224, 224))), [224, 224, 1]))\n",
    "\n",
    "            label = []\n",
    "            label.append(1 if example.features.feature['Atelectasis'].float_list.value[0] == 1 else 0)\n",
    "            label.append(1 if example.features.feature['Cardiomegaly'].float_list.value[0] == 1 else 0)\n",
    "            label.append(1 if example.features.feature['Consolidation'].float_list.value[0] == 1 else 0)\n",
    "            label.append(1 if example.features.feature['Edema'].float_list.value[0] == 1 else 0)\n",
    "            label.append(1 if example.features.feature['Enlarged Cardiomediastinum'].float_list.value[0] == 1 else 0)\n",
    "            label.append(1 if example.features.feature['Fracture'].float_list.value[0] == 1 else 0)\n",
    "            label.append(1 if example.features.feature['Lung Lesion'].float_list.value[0] == 1 else 0)\n",
    "            label.append(1 if example.features.feature['Lung Opacity'].float_list.value[0] == 1 else 0)\n",
    "            label.append(1 if example.features.feature['No Finding'].float_list.value[0] == 1 else 0)\n",
    "            label.append(1 if example.features.feature['Pleural Effusion'].float_list.value[0] == 1 else 0)\n",
    "            label.append(1 if example.features.feature['Pleural Other'].float_list.value[0] == 1 else 0)\n",
    "            label.append(1 if example.features.feature['Pneumonia'].float_list.value[0] == 1 else 0)\n",
    "            label.append(1 if example.features.feature['Pneumothorax'].float_list.value[0] == 1 else 0)\n",
    "            label.append(1 if example.features.feature['Support Devices'].float_list.value[0] == 1 else 0)\n",
    "\n",
    "\n",
    "            y.append(label)\n",
    "            \n",
    "        else:\n",
    "            X.append(0)\n",
    "            y.append(np.zeros(14))\n",
    "            \n",
    "        race = example.features.feature['race'].int64_list.value[0]\n",
    "        if (race == 4 and dataset == 'mimic'):\n",
    "            race = 2\n",
    "        age = example.features.feature['age'].int64_list.value[0]\n",
    "        if (age > 0 and dataset == 'mimic'):\n",
    "            age -= 1\n",
    "        gender = example.features.feature['gender'].int64_list.value[0]\n",
    "        \n",
    "        temp = [race, gender, age]\n",
    "#         {\"race\":race, \"gender\":gender, \"age\":age}\n",
    "        demo.append(temp)\n",
    "    \n",
    "    return np.array(X), np.array(y), np.array(demo)\n",
    "\n",
    "with tf.device('cpu'):\n",
    "    img_array, y, demo = get_data(dataset='mimic', label_type='Consolidation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_name = 'predictions/model_densenet_mimic_ERM_on_original'\n",
    "\n",
    "with open(prediction_name, \"rb\") as fp:\n",
    "    y_preds_0 = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "\n",
    "prediction_name = 'predictions/model_densenet_mimic_ERM_proposed_on_original'\n",
    "\n",
    "with open(prediction_name, \"rb\") as fp:\n",
    "    y_preds_1 = pickle.load(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_conv_model(model):\n",
    "    input_layer = model.get_layer(model.layers[0].name)\n",
    "    upsampling = model.get_layer(model.layers[1].name)\n",
    "    denset121 = model.get_layer(model.layers[2].name)\n",
    "\n",
    "    last_conv_layer_model = tf.keras.Sequential()\n",
    "    last_conv_layer_model.add(input_layer)\n",
    "    last_conv_layer_model.add(upsampling)\n",
    "    last_conv_layer_model.add(tf.keras.Model(denset121.inputs, denset121.layers[-4].output))\n",
    "    \n",
    "    # Second, we create a model that maps the activations of the last conv\n",
    "    # layer to the final class predictions\n",
    "    classifier_input = tf.keras.Input(shape=denset121.layers[-3].output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer in denset121.layers[-3:]:\n",
    "        x = denset121.get_layer(layer.name)(x)\n",
    "    x = model.get_layer(model.layers[-1].name)(x)\n",
    "    classifier_model = tf.keras.Model(classifier_input, x)   \n",
    "    \n",
    "    return last_conv_layer_model, classifier_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = ''\n",
    "\n",
    "checkpoint_name = 'model_densenet_mimic_ERM{}'.format(model_type)\n",
    "    \n",
    "model = get_model('ERM', '', 'disease', 'densenet')\n",
    "checkpoint = tf.train.Checkpoint(model)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+checkpoint_name, max_to_keep=1, checkpoint_name=checkpoint_name)\n",
    "model.load_weights(manager.checkpoints[0])\n",
    "model_last_conv, model_classifier = get_last_conv_model(model)\n",
    "\n",
    "checkpoint_name = 'model_densenet_mimic_ERM_race{}'.format(model_type)\n",
    "    \n",
    "model_race = get_model('ERM', '', 'race', 'densenet')\n",
    "checkpoint = tf.train.Checkpoint(model_race)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+checkpoint_name, max_to_keep=1, checkpoint_name=checkpoint_name)\n",
    "model_race.load_weights(manager.checkpoints[0])\n",
    "model_race_last_conv, model_race_classifier = get_last_conv_model(model_race)\n",
    "\n",
    "checkpoint_name = 'model_densenet_mimic_ERM_age{}'.format(model_type)\n",
    "    \n",
    "model_age = get_model('ERM', '', 'age', 'densenet')\n",
    "checkpoint = tf.train.Checkpoint(model_age)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+checkpoint_name, max_to_keep=1, checkpoint_name=checkpoint_name)\n",
    "model_age.load_weights(manager.checkpoints[0])\n",
    "model_age_last_conv, model_age_classifier = get_last_conv_model(model_age)\n",
    "\n",
    "checkpoint_name = 'model_densenet_mimic_ERM_gender{}'.format(model_type)\n",
    "    \n",
    "model_gender = get_model('ERM', '', 'gender', 'densenet')\n",
    "checkpoint = tf.train.Checkpoint(model_gender)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+checkpoint_name, max_to_keep=1, checkpoint_name=checkpoint_name)\n",
    "model_gender.load_weights(manager.checkpoints[0])\n",
    "model_gender_last_conv, model_gender_classifier = get_last_conv_model(model_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = 2\n",
    "idx = np.where(y[:, target_class]==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresh_0 = np.loadtxt('thresh/model_densenet_mimic_ERM_thresh.txt')\n",
    "best_thresh_1 = np.loadtxt('thresh/model_densenet_mimic_ERM_proposed_thresh.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx_0 = np.where(y_preds_0[idx, target_class] < best_thresh_0[target_class])[0]\n",
    "valid_idx_1 = np.where(y_preds_1[idx, target_class] > best_thresh_1[target_class])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx = np.intersect1d(valid_idx_0, valid_idx_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in valid_idx:\n",
    "    print(i)\n",
    "    \n",
    "    plt.figure(figsize=(3, 1.5), dpi=300)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    \n",
    "    ax1 = plt.subplot(141)\n",
    "    ax1.set_title('Disease', size=5)\n",
    "    ax1.axis('off')\n",
    "    jet_heatmap = show_heatmap(np.reshape(img_array[idx][i], (1, 224, 224, 1)), model_last_conv, model_classifier, target_class=target_class)\n",
    "    ax1.imshow((jet_heatmap/255)*0.4+img_array[idx][i])\n",
    "    \n",
    "    ax2 = plt.subplot(142)\n",
    "    ax2.set_title('Race', size=5)\n",
    "    ax2.axis('off')\n",
    "    jet_heatmap = show_heatmap(np.reshape(img_array[idx][i], (1, 224, 224, 1)), model_race_last_conv, model_race_classifier, target_class=None)\n",
    "    ax2.imshow((jet_heatmap/255)*0.4+img_array[idx][i])\n",
    "    \n",
    "    \n",
    "    ax3 = plt.subplot(143)\n",
    "    ax3.set_title('Age', size=5)\n",
    "    ax3.axis('off')\n",
    "    jet_heatmap = show_heatmap(np.reshape(img_array[idx][i], (1, 224, 224, 1)), model_age_last_conv, model_age_classifier, target_class=None)\n",
    "    ax3.imshow((jet_heatmap/255)*0.4+img_array[idx][i])\n",
    "    \n",
    "    ax4 = plt.subplot(144)\n",
    "    ax4.set_title('Gender', size=5)\n",
    "    ax4.axis('off')\n",
    "    jet_heatmap = show_heatmap(np.reshape(img_array[idx][i], (1, 224, 224, 1)), model_gender_last_conv, model_gender_classifier, target_class=None)\n",
    "    ax4.imshow((jet_heatmap/255)*0.4+img_array[idx][i])\n",
    "                               \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = '_proposed'\n",
    "\n",
    "checkpoint_name = 'model_densenet_mimic_ERM{}'.format(model_type)\n",
    "    \n",
    "model = get_model('ERM', '', 'disease', 'densenet')\n",
    "checkpoint = tf.train.Checkpoint(model)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+checkpoint_name, max_to_keep=1, checkpoint_name=checkpoint_name)\n",
    "model.load_weights(manager.checkpoints[0])\n",
    "model_last_conv, model_classifier = get_last_conv_model(model)\n",
    "\n",
    "checkpoint_name = 'model_densenet_mimic_ERM_race{}'.format(model_type)\n",
    "    \n",
    "model_race = get_model('ERM', '', 'race', 'densenet')\n",
    "checkpoint = tf.train.Checkpoint(model_race)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+checkpoint_name, max_to_keep=1, checkpoint_name=checkpoint_name)\n",
    "model_race.load_weights(manager.checkpoints[0])\n",
    "model_race_last_conv, model_race_classifier = get_last_conv_model(model_race)\n",
    "\n",
    "checkpoint_name = 'model_densenet_mimic_ERM_age{}'.format(model_type)\n",
    "    \n",
    "model_age = get_model('ERM', '', 'age', 'densenet')\n",
    "checkpoint = tf.train.Checkpoint(model_age)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+checkpoint_name, max_to_keep=1, checkpoint_name=checkpoint_name)\n",
    "model_age.load_weights(manager.checkpoints[0])\n",
    "model_age_last_conv, model_age_classifier = get_last_conv_model(model_age)\n",
    "\n",
    "checkpoint_name = 'model_densenet_mimic_ERM_gender{}'.format(model_type)\n",
    "    \n",
    "model_gender = get_model('ERM', '', 'gender', 'densenet')\n",
    "checkpoint = tf.train.Checkpoint(model_gender)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+checkpoint_name, max_to_keep=1, checkpoint_name=checkpoint_name)\n",
    "model_gender.load_weights(manager.checkpoints[0])\n",
    "model_gender_last_conv, model_gender_classifier = get_last_conv_model(model_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in valid_idx:\n",
    "    print(i)\n",
    "    \n",
    "    plt.figure(figsize=(3, 1.5), dpi=300)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    \n",
    "    ax1 = plt.subplot(141)\n",
    "    ax1.set_title('Disease', size=5)\n",
    "    ax1.axis('off')\n",
    "    jet_heatmap = show_heatmap(np.reshape(img_array[idx][i], (1, 224, 224, 1)), model_last_conv, model_classifier, target_class=target_class)\n",
    "    ax1.imshow((jet_heatmap/255)*0.4+img_array[idx][i])\n",
    "    \n",
    "    ax2 = plt.subplot(142)\n",
    "    ax2.set_title('Race', size=5)\n",
    "    ax2.axis('off')\n",
    "    jet_heatmap = show_heatmap(np.reshape(img_array[idx][i], (1, 224, 224, 1)), model_race_last_conv, model_race_classifier, target_class=None)\n",
    "    ax2.imshow((jet_heatmap/255)*0.4+img_array[idx][i])\n",
    "    \n",
    "    \n",
    "    ax3 = plt.subplot(143)\n",
    "    ax3.set_title('Age', size=5)\n",
    "    ax3.axis('off')\n",
    "    jet_heatmap = show_heatmap(np.reshape(img_array[idx][i], (1, 224, 224, 1)), model_age_last_conv, model_age_classifier, target_class=None)\n",
    "    ax3.imshow((jet_heatmap/255)*0.4+img_array[idx][i])\n",
    "    \n",
    "    ax4 = plt.subplot(144)\n",
    "    ax4.set_title('Gender', size=5)\n",
    "    ax4.axis('off')\n",
    "    jet_heatmap = show_heatmap(np.reshape(img_array[idx][i], (1, 224, 224, 1)), model_gender_last_conv, model_gender_classifier, target_class=None)\n",
    "    ax4.imshow((jet_heatmap/255)*0.4+img_array[idx][i])\n",
    "                               \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'model_densenet_mimic_ERM'\n",
    "    \n",
    "baseline_model = get_model('ERM', '', 'disease', 'densenet')\n",
    "checkpoint = tf.train.Checkpoint(baseline_model)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+checkpoint_name, max_to_keep=1, checkpoint_name=checkpoint_name)\n",
    "baseline_model.load_weights(manager.checkpoints[0])\n",
    "baseline_model_last_conv, baseline_model_classifier = get_last_conv_model(baseline_model)\n",
    "\n",
    "\n",
    "checkpoint_name = 'model_densenet_mimic_ERM_proposed'\n",
    "\n",
    "proposed_model = get_model('ERM', '', 'disease', 'densenet')\n",
    "checkpoint = tf.train.Checkpoint(proposed_model)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='checkpoints/'+checkpoint_name, max_to_keep=1, checkpoint_name=checkpoint_name)\n",
    "proposed_model.load_weights(manager.checkpoints[0])\n",
    "proposed_model_last_conv, proposed_model_classifier = get_last_conv_model(proposed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-district",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in valid_idx:\n",
    "    print(i)\n",
    "    \n",
    "    plt.figure(figsize=(3, 1.5), dpi=300)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    \n",
    "    ax1 = plt.subplot(161)\n",
    "    ax1.axis('off')\n",
    "    jet_heatmap = show_heatmap(np.reshape(img_array[idx][i], (1, 224, 224, 1)), proposed_model_last_conv, proposed_model_classifier, target_class=target_class)\n",
    "    ax1.imshow(jet_heatmap[0])\n",
    "    \n",
    "    ax2 = plt.subplot(162)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    smap = np.abs(compute_smap(img_array[idx][i], proposed_model_last_conv))\n",
    "    ax2.imshow(img_array[idx][i], cmap='gray')\n",
    "    ax2.imshow(smap, cmap='Reds', alpha=0.6)\n",
    "    \n",
    "    ax3 = plt.subplot(163)\n",
    "    ax3.axis('off')\n",
    "    jet_heatmap = grad_cam_plus(np.reshape(img_array[idx][i], (1, 224, 224, 1)), proposed_model_last_conv, proposed_model_classifier, target_class=target_class)\n",
    "    ax3.imshow(jet_heatmap)\n",
    "    \n",
    "    ax4 = plt.subplot(164)\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    jet_heatmap = show_heatmap(np.reshape(img_array[idx][i], (1, 224, 224, 1)), baseline_model_last_conv, baseline_model_classifier, target_class=target_class)\n",
    "    ax4.imshow(jet_heatmap[0])\n",
    "    \n",
    "    ax5 = plt.subplot(165)\n",
    "    smap = np.abs(compute_smap(img_array[idx][i], baseline_model_last_conv))\n",
    "    ax5.imshow(img_array[idx][i], cmap='gray')\n",
    "    ax4.imshow(smap, cmap='Reds', alpha=0.6)\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    ax6 = plt.subplot(166)\n",
    "    ax6.axis('off')\n",
    "    jet_heatmap = grad_cam_plus(np.reshape(img_array[idx][i], (1, 224, 224, 1)), baseline_model_last_conv, baseline_model_classifier, target_class=target_class)\n",
    "    ax6.imshow(jet_heatmap)\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-citizen",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [1435, 2469, 2598, 2621, 2647]:\n",
    "    print(i)\n",
    "    \n",
    "    fig, ax = plt.subplots(4, 2, figsize=(6, 3), dpi=400)\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    \n",
    "    ax[0, 0].axis('off')\n",
    "    ax[0, 0].set_title('Baseline model', size=5)\n",
    "    ax[0, 0].imshow(img_array[idx][i], cmap='gray')\n",
    "    \n",
    "    ax[0, 1].axis('off')\n",
    "    ax[0, 1].set_title('Proposed model', size=5)\n",
    "    ax[0, 1].imshow(img_array[idx][i], cmap='gray')\n",
    "    \n",
    "    ax[1, 0].axis('off')\n",
    "    ax[1, 0].set_title('GradCAM', size=3)\n",
    "    jet_heatmap = show_heatmap(np.reshape(img_array[idx][i], (1, 224, 224, 1)), baseline_model_last_conv, baseline_model_classifier, target_class=target_class)\n",
    "    ax[1, 0].imshow((jet_heatmap/255)*0.4+img_array[idx][i])\n",
    "    \n",
    "    ax[2, 0].axis('off')\n",
    "    ax[2, 0].set_title('GradCAM++', size=3)\n",
    "    jet_heatmap = grad_cam_plus(np.reshape(img_array[idx][i], (1, 224, 224, 1)), baseline_model_last_conv, baseline_model_classifier, target_class=target_class)\n",
    "    jet_heatmap = np.abs(jet_heatmap - 255)\n",
    "    ax[2, 0].imshow((jet_heatmap/255)*0.4+img_array[idx][i])\n",
    "    \n",
    "    ax[3, 0].axis('off')\n",
    "    ax[3, 0].set_title('Saliency map', size=3)\n",
    "    smap = np.abs(compute_smap(img_array[idx][i], baseline_model_last_conv))\n",
    "    ax[3, 0].imshow(img_array[idx][i], cmap='gray')\n",
    "    ax[3, 0].imshow(smap, cmap='Reds', alpha=0.6)\n",
    "    \n",
    "    ax[1, 1].axis('off')\n",
    "    ax[1, 1].set_title('GradCAM', size=3)\n",
    "    jet_heatmap = show_heatmap(np.reshape(img_array[idx][i], (1, 224, 224, 1)), proposed_model_last_conv, proposed_model_classifier, target_class=target_class)\n",
    "    ax[1, 1].imshow((jet_heatmap/255)*0.4+img_array[idx][i])\n",
    "    \n",
    "    ax[2, 1].axis('off')\n",
    "    ax[2, 1].set_title('GradCAM++', size=3)\n",
    "    jet_heatmap = grad_cam_plus(np.reshape(img_array[idx][i], (1, 224, 224, 1)), proposed_model_last_conv, proposed_model_classifier, target_class=target_class)\n",
    "    jet_heatmap = np.abs(jet_heatmap - 255)\n",
    "    ax[2, 1].imshow((jet_heatmap/255)*0.4+img_array[idx][i])\n",
    "    \n",
    "    ax[3, 1].axis('off')\n",
    "    ax[3, 1].set_title('Saliency map', size=3)\n",
    "    smap = np.abs(compute_smap(img_array[idx][i], proposed_model_last_conv))\n",
    "    ax[3, 1].imshow(img_array[idx][i], cmap='gray')\n",
    "    ax[3, 1].imshow(smap, cmap='Reds', alpha=0.6)\n",
    "    \n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1435, 2469, 2598, 2621, 2647]:\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "    plt.axis('off')\n",
    "    jet_heatmap = grad_cam_plus(np.reshape(img_array[idx][i], (1, 224, 224, 1)), proposed_model_last_conv, proposed_model_classifier, target_class=target_class)\n",
    "    jet_heatmap = np.abs(jet_heatmap - 255)\n",
    "    plt.imshow((jet_heatmap/255)*0.4+img_array[idx][i])\n",
    "    \n",
    "    plt.savefig('plots/gradcampp_proposed_{}.jpg'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1435, 2469, 2598, 2621, 2647]:\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "    plt.axis('off')\n",
    "    jet_heatmap = grad_cam_plus(np.reshape(img_array[idx][i], (1, 224, 224, 1)), baseline_model_last_conv, baseline_model_classifier, target_class=target_class)\n",
    "    jet_heatmap = np.abs(jet_heatmap - 255)\n",
    "    plt.imshow((jet_heatmap/255)*0.4+img_array[idx][i])\n",
    "    \n",
    "    plt.savefig('plots/gradcampp_baseline_{}.jpg'.format(i))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
